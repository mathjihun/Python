{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Linear regression.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNQo3GV6LUl0TDv9aIIQHMR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["###**훈련 데이터셋의 구성**"],"metadata":{"id":"-f_1oQ9w5-hR"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"kD52A82Dz9v2"},"outputs":[],"source":["x_train = torch.FloatTensor([[1], [2], [3]])\n","y_train = torch.FloatTensor([[2], [4], [6]])"]},{"cell_type":"markdown","source":["###**가설 수립**\n","\n","선형 회귀란 학습 데이터와 가장 잘 맞는 하나의 직선을 찾는 일입니다.  \n","$ y = Wx+b $\n","이때 $x$와 곱해지는 $W$를 가중치(weight)라고 하고, $b$를 편향(bias)이라고 합니다.  \n","\n","경사 하강법(Gradient Descent)\n","loss는 기울기 $W$가 커질수록 커집니다. loss가 최소가 되는 적당한 $W$를 찾기 위해 임의의 초기값 $W$를 정하고 gradient 방향으로 $\\alpha$배 만큼 조금씩 이동시켜 주어야 합니다. \n","\n","여기서 $\\alpha$는 learning rate를 의미합니다.\n","learning rate가 너무 크다면 최솟값을 찾아가지 못하고 오히려 발산하는 결과를 초래하고 learning rate가 너무 작다면 최솟값을 찾아가는데 너무 오랜 시간이 걸립니다."],"metadata":{"id":"EXmGTgyO61ZY"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim"],"metadata":{"id":"WL-Woaum7wKU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7DuKhf8eEHzH","executionInfo":{"status":"ok","timestamp":1659597408257,"user_tz":-540,"elapsed":21,"user":{"displayName":"송지훈/학생/수학","userId":"03961226534585665987"}},"outputId":"e008a99a-12b2-4ce8-c112-055982b5370c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f5e42f0a910>"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["x_train = torch.FloatTensor([[1], [2], [3]])\n","y_train = torch.FloatTensor([[2], [4], [6]])\n","\n","W = torch.zeros(1, requires_grad=True)    # 학습을 통해 계속 변경되도록 requires_grad = True를 준 것이다.\n","b = torch.zeros(1, requires_grad=True)    # True가 아닌 False로 하게 될 경우 역전파를 진행할 때 이 Tensor들을 update하지 않겠다는 것이다.\n","\n","optimizer = optim.SGD([W, b], lr=0.01)    # optimizer 설정\n","\n","nb_epochs = 2000\n","for epoch in range(nb_epochs + 1):\n","  hypothesis = x_train * W + b    # H(x) = Wx + b\n","  \n","  cost = torch.mean((hypothesis - y_train) ** 2)   # MSE\n","\n","  optimizer.zero_grad()    # gradient를 0으로 초기화\n","  cost.backward()     # 비용 함수를 미분하여 gradient 계산\n","  optimizer.step()    # W와 b를 업데이트\n","\n","  if epoch % 100 == 0:\n","    print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n","        epoch, nb_epochs, W.item(), b.item(), cost.item()         # tensor에 저장된 값만을 가져오려면 item()을 사용해주면 된다.\n","    ))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dh61-Di7ETe1","executionInfo":{"status":"ok","timestamp":1659587493725,"user_tz":-540,"elapsed":620,"user":{"displayName":"송지훈/학생/수학","userId":"03961226534585665987"}},"outputId":"dd325d19-b1c9-4e04-b946-503fae9fcd53"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch    0/2000 W: 0.187, b: 0.080 Cost: 18.666666\n","Epoch  100/2000 W: 1.746, b: 0.578 Cost: 0.048171\n","Epoch  200/2000 W: 1.800, b: 0.454 Cost: 0.029767\n","Epoch  300/2000 W: 1.843, b: 0.357 Cost: 0.018394\n","Epoch  400/2000 W: 1.876, b: 0.281 Cost: 0.011366\n","Epoch  500/2000 W: 1.903, b: 0.221 Cost: 0.007024\n","Epoch  600/2000 W: 1.924, b: 0.174 Cost: 0.004340\n","Epoch  700/2000 W: 1.940, b: 0.136 Cost: 0.002682\n","Epoch  800/2000 W: 1.953, b: 0.107 Cost: 0.001657\n","Epoch  900/2000 W: 1.963, b: 0.084 Cost: 0.001024\n","Epoch 1000/2000 W: 1.971, b: 0.066 Cost: 0.000633\n","Epoch 1100/2000 W: 1.977, b: 0.052 Cost: 0.000391\n","Epoch 1200/2000 W: 1.982, b: 0.041 Cost: 0.000242\n","Epoch 1300/2000 W: 1.986, b: 0.032 Cost: 0.000149\n","Epoch 1400/2000 W: 1.989, b: 0.025 Cost: 0.000092\n","Epoch 1500/2000 W: 1.991, b: 0.020 Cost: 0.000057\n","Epoch 1600/2000 W: 1.993, b: 0.016 Cost: 0.000035\n","Epoch 1700/2000 W: 1.995, b: 0.012 Cost: 0.000022\n","Epoch 1800/2000 W: 1.996, b: 0.010 Cost: 0.000013\n","Epoch 1900/2000 W: 1.997, b: 0.008 Cost: 0.000008\n","Epoch 2000/2000 W: 1.997, b: 0.006 Cost: 0.000005\n"]}]},{"cell_type":"markdown","source":["###**optimizer.zero_grad()가 필요한 이유**"],"metadata":{"id":"hQDkCYThIKZt"}},{"cell_type":"code","source":["w = torch.tensor(2.0, requires_grad=True)\n","\n","nb_epochs = 20\n","\n","for epoch in range(nb_epochs + 1):\n","  z = 2*w\n","\n","  z.backward()\n","  print(\"수식을 w로 미분한 값: {}\".format(w.grad))\n","\n","# 결과에서 볼 수 있듯이 원래라면 2가 나와야하는데 이를 누적해서 더해주는 효과가 발생한다. 그래서 0으로 항상 초기화를 해줘야 한다."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B-29SgImE8vP","executionInfo":{"status":"ok","timestamp":1659588632204,"user_tz":-540,"elapsed":621,"user":{"displayName":"송지훈/학생/수학","userId":"03961226534585665987"}},"outputId":"33dd99bf-1996-40e0-e8bd-fcbe7dceed7b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["수식을 w로 미분한 값: 2.0\n","수식을 w로 미분한 값: 4.0\n","수식을 w로 미분한 값: 6.0\n","수식을 w로 미분한 값: 8.0\n","수식을 w로 미분한 값: 10.0\n","수식을 w로 미분한 값: 12.0\n","수식을 w로 미분한 값: 14.0\n","수식을 w로 미분한 값: 16.0\n","수식을 w로 미분한 값: 18.0\n","수식을 w로 미분한 값: 20.0\n","수식을 w로 미분한 값: 22.0\n","수식을 w로 미분한 값: 24.0\n","수식을 w로 미분한 값: 26.0\n","수식을 w로 미분한 값: 28.0\n","수식을 w로 미분한 값: 30.0\n","수식을 w로 미분한 값: 32.0\n","수식을 w로 미분한 값: 34.0\n","수식을 w로 미분한 값: 36.0\n","수식을 w로 미분한 값: 38.0\n","수식을 w로 미분한 값: 40.0\n","수식을 w로 미분한 값: 42.0\n"]}]},{"cell_type":"markdown","source":["###**자동 미분 Autograd**"],"metadata":{"id":"hlxchte1t0Lh"}},{"cell_type":"code","source":["import torch"],"metadata":{"id":"604lxgCUIiK3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["w = torch.tensor(2.0, requires_grad=True)\n","y = w**2\n","z = 2*y + 5\n","\n","z.backward()\n","\n","print(\"수식을 w로 미분한 값: {}\".format(w.grad))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6bWLCKfXKp4D","executionInfo":{"status":"ok","timestamp":1659601591064,"user_tz":-540,"elapsed":266,"user":{"displayName":"송지훈/학생/수학","userId":"03961226534585665987"}},"outputId":"5bc210c3-ae75-4366-98d5-23c0965c2abd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["수식을 w로 미분한 값: 8.0\n"]}]},{"cell_type":"markdown","source":["###**다중 선형 회귀**"],"metadata":{"id":"AY63GrXM-2Gb"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim"],"metadata":{"id":"V73UP3zq9mLG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oYFtt45XAanF","executionInfo":{"status":"ok","timestamp":1659602325708,"user_tz":-540,"elapsed":276,"user":{"displayName":"송지훈/학생/수학","userId":"03961226534585665987"}},"outputId":"e531448c-dcce-44f1-de8a-b811104747c6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f5e42f0a910>"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["$H(x)=w_1x_1+w_2x_2+w_3x_3+b$"],"metadata":{"id":"TLUYy_ONAem7"}},{"cell_type":"code","source":["x1_train = torch.FloatTensor([73, 93, 89, 96, 73]).unsqueeze(dim=1)\n","x2_train = torch.FloatTensor([80, 88, 91, 98, 66]).unsqueeze(dim=1)\n","x3_train = torch.FloatTensor([75, 93, 90, 100, 70]).unsqueeze(dim=1)\n","y_train = torch.FloatTensor([152, 185, 180, 196, 142]).unsqueeze(dim=1)\n","\n","w1 = torch.zeros(1, requires_grad=True)\n","w2 = torch.zeros(1, requires_grad=True)\n","w3 = torch.zeros(1, requires_grad=True)\n","b = torch.zeros(1, requires_grad=True)\n","\n","optimizer = optim.SGD([w1, w2, w3, b], lr=1e-5)\n","\n","nb_epochs = 1000\n","\n","for epoch in range(nb_epochs + 1):\n","  hypothesis = x1_train * w1 + x2_train * w2 + x3_train * w3 + b\n","\n","  cost = torch.mean((hypothesis - y_train) ** 2)\n","\n","  optimizer.zero_grad()\n","  cost.backward()\n","  optimizer.step()\n","\n","  if epoch % 100 == 0:\n","    print('Epoch {:4d}/{} w1: {:.3f} w2: {:.3f} w3: {:.3f} b: {:.3f} Cost: {:.6f}'.format(\n","        epoch, nb_epochs, w1.item(), w2.item(), w3.item(), b.item(), cost.item()\n","    ))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MlqkARNuAb-1","executionInfo":{"status":"ok","timestamp":1659605204235,"user_tz":-540,"elapsed":456,"user":{"displayName":"송지훈/학생/수학","userId":"03961226534585665987"}},"outputId":"6ff60352-2134-4b3c-b5b7-40593989c679"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch    0/1000 w1: 0.294 w2: 0.294 w3: 0.297 b: 0.003 Cost: 29661.800781\n","Epoch  100/1000 w1: 0.674 w2: 0.661 w3: 0.676 b: 0.008 Cost: 1.563628\n","Epoch  200/1000 w1: 0.679 w2: 0.655 w3: 0.677 b: 0.008 Cost: 1.497595\n","Epoch  300/1000 w1: 0.684 w2: 0.649 w3: 0.677 b: 0.008 Cost: 1.435044\n","Epoch  400/1000 w1: 0.689 w2: 0.643 w3: 0.678 b: 0.008 Cost: 1.375726\n","Epoch  500/1000 w1: 0.694 w2: 0.638 w3: 0.678 b: 0.009 Cost: 1.319507\n","Epoch  600/1000 w1: 0.699 w2: 0.633 w3: 0.679 b: 0.009 Cost: 1.266222\n","Epoch  700/1000 w1: 0.704 w2: 0.627 w3: 0.679 b: 0.009 Cost: 1.215703\n","Epoch  800/1000 w1: 0.709 w2: 0.622 w3: 0.679 b: 0.009 Cost: 1.167810\n","Epoch  900/1000 w1: 0.713 w2: 0.617 w3: 0.680 b: 0.009 Cost: 1.122429\n","Epoch 1000/1000 w1: 0.718 w2: 0.613 w3: 0.680 b: 0.009 Cost: 1.079390\n"]}]},{"cell_type":"markdown","source":["###$H(X)=XW+b$"],"metadata":{"id":"JgTJ-UXDQDmF"}},{"cell_type":"code","source":["x_train  =  torch.FloatTensor([[73,  80,  75], \n","                               [93,  88,  93], \n","                               [89,  91,  80], \n","                               [96,  98,  100],   \n","                               [73,  66,  70]])  \n","y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])\n","\n","W = torch.zeros((3, 1), requires_grad=True)\n","b = torch.zeros(1, requires_grad=True)     # x_train: 5 x 3, W: 3 x 1  =>  XW : 5 x 1인데 b는 1x1이므로 broadcasting에 의하여 5개 모두 같은 값으로 더해진다.\n","\n","optimizer = optim.SGD([W, b], lr=1e-5)\n","\n","nb_epochs = 20\n","\n","for epoch in range(nb_epochs + 1):\n","  hypothesis = x_train@W + b\n","\n","  cost = torch.mean((hypothesis - y_train) ** 2)\n","\n","  optimizer.zero_grad()\n","  cost.backward()\n","  optimizer.step()\n","  \n","  print('Epoch {:4d}/{} hypothesis: {} Cost: {:.6f}'.format(\n","        epoch, nb_epochs, hypothesis.squeeze().detach(), cost.item()\n","  ))\n","  \n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uO_61V37AvsG","executionInfo":{"status":"ok","timestamp":1659607328180,"user_tz":-540,"elapsed":368,"user":{"displayName":"송지훈/학생/수학","userId":"03961226534585665987"}},"outputId":"6bc9111a-ba48-4276-9fcf-4e7ad05a0e30"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch    0/20 hypothesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n","Epoch    1/20 hypothesis: tensor([66.7178, 80.1701, 76.1025, 86.0194, 61.1565]) Cost: 9537.694336\n","Epoch    2/20 hypothesis: tensor([104.5421, 125.6208, 119.2478, 134.7862,  95.8280]) Cost: 3069.590088\n","Epoch    3/20 hypothesis: tensor([125.9858, 151.3882, 143.7087, 162.4333, 115.4844]) Cost: 990.670288\n","Epoch    4/20 hypothesis: tensor([138.1429, 165.9963, 157.5768, 178.1071, 126.6283]) Cost: 322.481873\n","Epoch    5/20 hypothesis: tensor([145.0350, 174.2780, 165.4395, 186.9928, 132.9461]) Cost: 107.717064\n","Epoch    6/20 hypothesis: tensor([148.9423, 178.9730, 169.8976, 192.0301, 136.5279]) Cost: 38.687496\n","Epoch    7/20 hypothesis: tensor([151.1574, 181.6346, 172.4254, 194.8856, 138.5585]) Cost: 16.499043\n","Epoch    8/20 hypothesis: tensor([152.4131, 183.1435, 173.8590, 196.5043, 139.7097]) Cost: 9.365656\n","Epoch    9/20 hypothesis: tensor([153.1250, 183.9988, 174.6723, 197.4217, 140.3625]) Cost: 7.071114\n","Epoch   10/20 hypothesis: tensor([153.5285, 184.4835, 175.1338, 197.9415, 140.7325]) Cost: 6.331847\n","Epoch   11/20 hypothesis: tensor([153.7572, 184.7582, 175.3958, 198.2360, 140.9424]) Cost: 6.092532\n","Epoch   12/20 hypothesis: tensor([153.8868, 184.9138, 175.5449, 198.4026, 141.0613]) Cost: 6.013817\n","Epoch   13/20 hypothesis: tensor([153.9602, 185.0019, 175.6299, 198.4969, 141.1288]) Cost: 5.986785\n","Epoch   14/20 hypothesis: tensor([154.0017, 185.0517, 175.6785, 198.5500, 141.1671]) Cost: 5.976325\n","Epoch   15/20 hypothesis: tensor([154.0252, 185.0798, 175.7065, 198.5800, 141.1888]) Cost: 5.971208\n","Epoch   16/20 hypothesis: tensor([154.0385, 185.0956, 175.7229, 198.5966, 141.2012]) Cost: 5.967835\n","Epoch   17/20 hypothesis: tensor([154.0459, 185.1045, 175.7326, 198.6059, 141.2082]) Cost: 5.964969\n","Epoch   18/20 hypothesis: tensor([154.0501, 185.1094, 175.7386, 198.6108, 141.2122]) Cost: 5.962291\n","Epoch   19/20 hypothesis: tensor([154.0524, 185.1120, 175.7424, 198.6134, 141.2145]) Cost: 5.959664\n","Epoch   20/20 hypothesis: tensor([154.0536, 185.1134, 175.7451, 198.6145, 141.2158]) Cost: 5.957089\n"]}]},{"cell_type":"markdown","source":["###**nn.Module로 구현하는 선형 회귀**"],"metadata":{"id":"sNOeG4RNUeB4"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"],"metadata":{"id":"GzTCkKnWTiIY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"khTlnh9OUo6r","executionInfo":{"status":"ok","timestamp":1659607632851,"user_tz":-540,"elapsed":296,"user":{"displayName":"송지훈/학생/수학","userId":"03961226534585665987"}},"outputId":"072801e4-70b6-44a7-bd47-1cb39af96db9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f5e42f0a910>"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["x_train = torch.FloatTensor([[1], [2], [3]])\n","y_train = torch.FloatTensor([[2], [4], [6]])\n","\n","model = nn.Linear(1, 1)\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n","\n","nb_epochs = 2000\n","\n","for epoch in range(nb_epochs + 1):\n","  prediction = model(x_train)\n","\n","  cost = F.mse_loss(prediction, y_train)   # torch.nn.functional에서 loss function을 제공한다.\n","\n","  optimizer.zero_grad()\n","  cost.backward()\n","  optimizer.step()\n","\n","  if epoch % 100 == 0:\n","    print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n","          epoch, nb_epochs, cost.item()\n","    ))\n","\n","new_y = torch.FloatTensor([[4.0]])\n","pred_y = model(new_y)\n","\n","print(\"model이 훈련된 뒤 4.0일 때의 모델의 예측값: \", pred_y)\n","\n","print(list(model.parameters()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qWH7XZFiUsjG","executionInfo":{"status":"ok","timestamp":1659608328983,"user_tz":-540,"elapsed":847,"user":{"displayName":"송지훈/학생/수학","userId":"03961226534585665987"}},"outputId":"790748ab-d10d-4242-8c5e-1731a029bf58"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch    0/2000 Cost: 15.171722\n","Epoch  100/2000 Cost: 0.006754\n","Epoch  200/2000 Cost: 0.004174\n","Epoch  300/2000 Cost: 0.002579\n","Epoch  400/2000 Cost: 0.001594\n","Epoch  500/2000 Cost: 0.000985\n","Epoch  600/2000 Cost: 0.000609\n","Epoch  700/2000 Cost: 0.000376\n","Epoch  800/2000 Cost: 0.000232\n","Epoch  900/2000 Cost: 0.000144\n","Epoch 1000/2000 Cost: 0.000089\n","Epoch 1100/2000 Cost: 0.000055\n","Epoch 1200/2000 Cost: 0.000034\n","Epoch 1300/2000 Cost: 0.000021\n","Epoch 1400/2000 Cost: 0.000013\n","Epoch 1500/2000 Cost: 0.000008\n","Epoch 1600/2000 Cost: 0.000005\n","Epoch 1700/2000 Cost: 0.000003\n","Epoch 1800/2000 Cost: 0.000002\n","Epoch 1900/2000 Cost: 0.000001\n","Epoch 2000/2000 Cost: 0.000001\n","model이 훈련된 뒤 4.0일 때의 모델의 예측값:  tensor([[7.9983]], grad_fn=<AddmmBackward0>)\n","[Parameter containing:\n","tensor([[1.9990]], requires_grad=True), Parameter containing:\n","tensor([0.0022], requires_grad=True)]\n"]}]},{"cell_type":"code","source":["x_train = torch.FloatTensor([[73, 80, 75],\n","                             [93, 88, 93],\n","                             [89, 91, 90],\n","                             [96, 98, 100],\n","                             [73, 66, 70]])\n","y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n","\n","model = nn.Linear(3, 1)\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)\n","\n","nb_epochs = 2000\n","\n","for epoch in range(nb_epochs + 1):\n","  prediction = model(x_train)\n","\n","  cost = F.mse_loss(prediction, y_train)   # torch.nn.functional에서 loss function을 제공한다.\n","\n","  optimizer.zero_grad()\n","  cost.backward()\n","  optimizer.step()\n","\n","  if epoch % 100 == 0:\n","    print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n","          epoch, nb_epochs, cost.item()\n","    ))\n","\n","new_y = torch.FloatTensor([[4.0, 3.0, 2.0]])\n","pred_y = model(new_y)\n","\n","print(\"model이 훈련된 뒤 [4.0, 3.0, 2.0]일 때의 모델의 예측값: \", pred_y)\n","\n","print(list(model.parameters()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CyGXuN-ZWavS","executionInfo":{"status":"ok","timestamp":1659609713837,"user_tz":-540,"elapsed":326,"user":{"displayName":"송지훈/학생/수학","userId":"03961226534585665987"}},"outputId":"d77e3cc3-78ae-4c80-fec8-92bbbe343d73"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch    0/2000 Cost: 29938.339844\n","Epoch  100/2000 Cost: 1.459696\n","Epoch  200/2000 Cost: 1.404118\n","Epoch  300/2000 Cost: 1.351442\n","Epoch  400/2000 Cost: 1.301445\n","Epoch  500/2000 Cost: 1.254035\n","Epoch  600/2000 Cost: 1.209076\n","Epoch  700/2000 Cost: 1.166424\n","Epoch  800/2000 Cost: 1.125966\n","Epoch  900/2000 Cost: 1.087573\n","Epoch 1000/2000 Cost: 1.051147\n","Epoch 1100/2000 Cost: 1.016586\n","Epoch 1200/2000 Cost: 0.983798\n","Epoch 1300/2000 Cost: 0.952660\n","Epoch 1400/2000 Cost: 0.923131\n","Epoch 1500/2000 Cost: 0.895094\n","Epoch 1600/2000 Cost: 0.868473\n","Epoch 1700/2000 Cost: 0.843199\n","Epoch 1800/2000 Cost: 0.819206\n","Epoch 1900/2000 Cost: 0.796417\n","Epoch 2000/2000 Cost: 0.774786\n","model이 훈련된 뒤 [4.0, 3.0, 2.0]일 때의 모델의 예측값:  tensor([[5.9878]], grad_fn=<AddmmBackward0>)\n","[Parameter containing:\n","tensor([[0.7137, 0.5326, 0.7632]], requires_grad=True), Parameter containing:\n","tensor([0.0088], requires_grad=True)]\n"]}]},{"cell_type":"markdown","source":["###**모델을 클래스로 구현**"],"metadata":{"id":"L0WOr0trgYHO"}},{"cell_type":"code","source":["class LinearRegressionModel(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.linear = nn.Linear(3, 1)\n","\n","  def forward(self, x):     # 함수 이름 바꾸면 안 된다. model의 객체를 생성 후 그 객체에 data를 넣을 때 자동 호출된다.\n","    return self.linear(x)\n","\n","if __name__ == \"__main__\":\n","  x_train = torch.FloatTensor([[73, 80, 75],\n","                             [93, 88, 93],\n","                             [89, 91, 90],\n","                             [96, 98, 100],\n","                             [73, 66, 70]])\n","  y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n","  \n","  model = LinearRegressionModel()\n","  optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)\n","\n","  nb_epochs = 2000\n","\n","  for epoch in range(nb_epochs+1):\n","    prediction = model(x_train)    # model(x_train)은 model.forward(x_train)와 동일함.\n","\n","    cost = F.mse_loss(prediction, y_train)\n","\n","    optimizer.zero_grad()\n","    cost.backward()\n","    optimizer.step()\n","\n","    if epoch % 100 == 0:\n","      print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n","          epoch, nb_epochs, cost.item()\n","      ))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1vwvIcBZXLOF","executionInfo":{"status":"ok","timestamp":1659611579771,"user_tz":-540,"elapsed":610,"user":{"displayName":"송지훈/학생/수학","userId":"03961226534585665987"}},"outputId":"af6f378b-c4ed-42d4-e8e0-e845b6d84887"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch    0/2000 Cost: 47375.710938\n","Epoch  100/2000 Cost: 0.844645\n","Epoch  200/2000 Cost: 0.815248\n","Epoch  300/2000 Cost: 0.787375\n","Epoch  400/2000 Cost: 0.760944\n","Epoch  500/2000 Cost: 0.735871\n","Epoch  600/2000 Cost: 0.712089\n","Epoch  700/2000 Cost: 0.689536\n","Epoch  800/2000 Cost: 0.668133\n","Epoch  900/2000 Cost: 0.647833\n","Epoch 1000/2000 Cost: 0.628584\n","Epoch 1100/2000 Cost: 0.610303\n","Epoch 1200/2000 Cost: 0.592965\n","Epoch 1300/2000 Cost: 0.576510\n","Epoch 1400/2000 Cost: 0.560903\n","Epoch 1500/2000 Cost: 0.546079\n","Epoch 1600/2000 Cost: 0.532007\n","Epoch 1700/2000 Cost: 0.518654\n","Epoch 1800/2000 Cost: 0.505976\n","Epoch 1900/2000 Cost: 0.493935\n","Epoch 2000/2000 Cost: 0.482503\n"]}]},{"cell_type":"markdown","source":["###**미니 배치와 데이터 로드**  \n","배치 경사 하강법은 경사 하강법을 할 때 전체 데이터의 일부만 보고 수행하므로 최적값으로 수렴하는 과정이 느리지만 계산량이 적어 더 빠릅니다.  \n","CPU와 GPU의 메모리가 2의 제곱수이므로 배치 크기가 2의 제곱수이면 데이터 송수신의 효율을 높일 수 있습니다."],"metadata":{"id":"f2PDVlZ0j6pT"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torch.utils.data import TensorDataset\n","from torch.utils.data import DataLoader"],"metadata":{"id":"WXTQtGvOsPOi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train = torch.FloatTensor([[73, 80, 75],\n","                             [93, 88, 93],\n","                             [89, 91, 90],\n","                             [96, 98, 100],\n","                             [73, 66, 70]])\n","y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n","\n","dataset = TensorDataset(x_train, y_train)\n","dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n","\n","model = nn.Linear(3, 1)\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)\n","\n","nb_epochs = 20\n","\n","for epoch in range(nb_epochs + 1):\n","  for batch_idx, samples in enumerate(dataloader):\n","    x_train, y_train = samples\n","    prediction = model(x_train)\n","\n","    cost = F.mse_loss(prediction, y_train)\n","\n","    optimizer.zero_grad()\n","    cost.backward()\n","    optimizer.step()\n","\n","    print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n","        epoch, nb_epochs, batch_idx+1, len(dataloader),\n","        cost.item()\n","    ))"],"metadata":{"id":"LbQnAm4-gtbJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###**Custom Dataset**"],"metadata":{"id":"K08WCtZKuRz2"}},{"cell_type":"code","source":["import torch\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader"],"metadata":{"id":"_lxcTWMSuXWr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CustomDataset(Dataset):\n","  def __init__(self):\n","    self.x_data = [[73, 80, 75],\n","                   [93, 88, 93],\n","                   [89, 91, 90],\n","                   [96, 98, 100],\n","                   [73, 66, 70]]\n","    self.y_data = [[152], [185], [180], [196], [142]]\n","\n","  def __len__(self): \n","    return len(self.x_data)\n","\n","  def __getitem__(self, idx): \n","    x = torch.FloatTensor(self.x_data[idx])\n","    y = torch.FloatTensor(self.y_data[idx])\n","    return x, y\n","\n","if __name__ == \"__main__\":\n","  dataset = CustomDataset()\n","  dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n","\n","  model = torch.nn.Linear(3, 1)\n","  optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)\n","\n","  nb_epochs = 20\n","\n","  for epoch in range(nb_epochs + 1):\n","    for batch_idx, samples in enumerate(dataloader):\n","      x_train, y_train = samples\n","      prediction = model(x_train)\n","\n","      cost = F.mse_loss(prediction, y_train)\n","\n","      optimizer.zero_grad()\n","      cost.backward()\n","      optimizer.step()\n","\n","      print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n","        epoch, nb_epochs, batch_idx+1, len(dataloader),\n","        cost.item()\n","      ))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fwUuoE_AuUOt","executionInfo":{"status":"ok","timestamp":1659617443885,"user_tz":-540,"elapsed":738,"user":{"displayName":"송지훈/학생/수학","userId":"03961226534585665987"}},"outputId":"c22c98ce-f4e0-43a6-8f3f-cb0a8ccf9f3c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch    0/20 Batch 1/3 Cost: 28056.785156\n","Epoch    0/20 Batch 2/3 Cost: 7443.491699\n","Epoch    0/20 Batch 3/3 Cost: 2924.795166\n","Epoch    1/20 Batch 1/3 Cost: 765.211670\n","Epoch    1/20 Batch 2/3 Cost: 276.749695\n","Epoch    1/20 Batch 3/3 Cost: 58.599709\n","Epoch    2/20 Batch 1/3 Cost: 35.451908\n","Epoch    2/20 Batch 2/3 Cost: 13.129348\n","Epoch    2/20 Batch 3/3 Cost: 1.266209\n","Epoch    3/20 Batch 1/3 Cost: 9.546274\n","Epoch    3/20 Batch 2/3 Cost: 2.845059\n","Epoch    3/20 Batch 3/3 Cost: 5.347515\n","Epoch    4/20 Batch 1/3 Cost: 2.534359\n","Epoch    4/20 Batch 2/3 Cost: 2.819185\n","Epoch    4/20 Batch 3/3 Cost: 5.662753\n","Epoch    5/20 Batch 1/3 Cost: 4.533195\n","Epoch    5/20 Batch 2/3 Cost: 1.572932\n","Epoch    5/20 Batch 3/3 Cost: 5.505545\n","Epoch    6/20 Batch 1/3 Cost: 1.481086\n","Epoch    6/20 Batch 2/3 Cost: 4.360450\n","Epoch    6/20 Batch 3/3 Cost: 6.482376\n","Epoch    7/20 Batch 1/3 Cost: 0.740106\n","Epoch    7/20 Batch 2/3 Cost: 3.656868\n","Epoch    7/20 Batch 3/3 Cost: 7.027564\n","Epoch    8/20 Batch 1/3 Cost: 2.455734\n","Epoch    8/20 Batch 2/3 Cost: 1.831991\n","Epoch    8/20 Batch 3/3 Cost: 7.753441\n","Epoch    9/20 Batch 1/3 Cost: 1.205312\n","Epoch    9/20 Batch 2/3 Cost: 7.290859\n","Epoch    9/20 Batch 3/3 Cost: 3.189180\n","Epoch   10/20 Batch 1/3 Cost: 4.637508\n","Epoch   10/20 Batch 2/3 Cost: 1.725379\n","Epoch   10/20 Batch 3/3 Cost: 2.935929\n","Epoch   11/20 Batch 1/3 Cost: 1.497915\n","Epoch   11/20 Batch 2/3 Cost: 3.125842\n","Epoch   11/20 Batch 3/3 Cost: 6.193594\n","Epoch   12/20 Batch 1/3 Cost: 1.730291\n","Epoch   12/20 Batch 2/3 Cost: 8.665751\n","Epoch   12/20 Batch 3/3 Cost: 0.000087\n","Epoch   13/20 Batch 1/3 Cost: 1.081492\n","Epoch   13/20 Batch 2/3 Cost: 4.939166\n","Epoch   13/20 Batch 3/3 Cost: 7.511059\n","Epoch   14/20 Batch 1/3 Cost: 4.850656\n","Epoch   14/20 Batch 2/3 Cost: 2.782715\n","Epoch   14/20 Batch 3/3 Cost: 0.018671\n","Epoch   15/20 Batch 1/3 Cost: 2.464139\n","Epoch   15/20 Batch 2/3 Cost: 2.249158\n","Epoch   15/20 Batch 3/3 Cost: 6.938131\n","Epoch   16/20 Batch 1/3 Cost: 1.710595\n","Epoch   16/20 Batch 2/3 Cost: 6.170294\n","Epoch   16/20 Batch 3/3 Cost: 3.769355\n","Epoch   17/20 Batch 1/3 Cost: 3.850657\n","Epoch   17/20 Batch 2/3 Cost: 4.615356\n","Epoch   17/20 Batch 3/3 Cost: 4.148136\n","Epoch   18/20 Batch 1/3 Cost: 2.554764\n","Epoch   18/20 Batch 2/3 Cost: 3.782027\n","Epoch   18/20 Batch 3/3 Cost: 2.427312\n","Epoch   19/20 Batch 1/3 Cost: 3.570935\n","Epoch   19/20 Batch 2/3 Cost: 2.342732\n","Epoch   19/20 Batch 3/3 Cost: 5.191786\n","Epoch   20/20 Batch 1/3 Cost: 3.603523\n","Epoch   20/20 Batch 2/3 Cost: 3.568414\n","Epoch   20/20 Batch 3/3 Cost: 4.839785\n"]}]}]}
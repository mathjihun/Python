{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Softmax Regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "jqJkORkE7apW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAhlUnxX3FnQ",
        "outputId": "794eb919-3811-49a9-adeb-8af622a0384a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/3000 Loss: 2.113073\n",
            "Epoch  100/3000 Loss: 0.648366\n",
            "Epoch  200/3000 Loss: 0.560265\n",
            "Epoch  300/3000 Loss: 0.504935\n",
            "Epoch  400/3000 Loss: 0.460156\n",
            "Epoch  500/3000 Loss: 0.420397\n",
            "Epoch  600/3000 Loss: 0.383207\n",
            "Epoch  700/3000 Loss: 0.347037\n",
            "Epoch  800/3000 Loss: 0.310732\n",
            "Epoch  900/3000 Loss: 0.274023\n",
            "Epoch 1000/3000 Loss: 0.244529\n",
            "Epoch 1100/3000 Loss: 0.231241\n",
            "Epoch 1200/3000 Loss: 0.220042\n",
            "Epoch 1300/3000 Loss: 0.209847\n",
            "Epoch 1400/3000 Loss: 0.200524\n",
            "Epoch 1500/3000 Loss: 0.191967\n",
            "Epoch 1600/3000 Loss: 0.184084\n",
            "Epoch 1700/3000 Loss: 0.176801\n",
            "Epoch 1800/3000 Loss: 0.170052\n",
            "Epoch 1900/3000 Loss: 0.163781\n",
            "Epoch 2000/3000 Loss: 0.157940\n",
            "Epoch 2100/3000 Loss: 0.152487\n",
            "Epoch 2200/3000 Loss: 0.147386\n",
            "Epoch 2300/3000 Loss: 0.142604\n",
            "Epoch 2400/3000 Loss: 0.138113\n",
            "Epoch 2500/3000 Loss: 0.133888\n",
            "Epoch 2600/3000 Loss: 0.129905\n",
            "Epoch 2700/3000 Loss: 0.126146\n",
            "Epoch 2800/3000 Loss: 0.122592\n",
            "Epoch 2900/3000 Loss: 0.119227\n",
            "Epoch 3000/3000 Loss: 0.116037\n"
          ]
        }
      ],
      "source": [
        "class SoftmaxClassifierModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(4, 3)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.linear(x)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  x_data = [[1, 2, 1, 1],\n",
        "           [2, 1, 3, 2],\n",
        "           [3, 1, 3, 4],\n",
        "           [4, 1, 5, 5],\n",
        "           [1, 7, 5, 5],\n",
        "           [1, 2, 5, 6],\n",
        "           [1, 6, 6, 6],\n",
        "           [1, 7, 7, 7]]\n",
        "  y_data = [2, 2, 2, 1, 1, 1, 0, 0]     # 답은 0, 1, 2 이렇게 3개만 존재한다고 가정\n",
        "  x_train = torch.FloatTensor(x_data)\n",
        "  y_train = torch.LongTensor(y_data)\n",
        "\n",
        "  model = SoftmaxClassifierModel()\n",
        "  criterion = nn.CrossEntropyLoss()    # 이미 nn.LogSoftmax가 포함되어 있다.\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)\n",
        "\n",
        "  nb_epochs = 3000\n",
        "\n",
        "  for epoch in range(nb_epochs+1):\n",
        "    prediction = model(x_train)\n",
        "\n",
        "    loss = criterion(prediction, y_train)    # criterion(input, target)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "      print('Epoch {:4d}/{} Loss: {:.6f}'.format(\n",
        "          epoch, nb_epochs, loss.item()\n",
        "      ))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**MNIST**"
      ],
      "metadata": {
        "id": "kM3yr5oe-dVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import time"
      ],
      "metadata": {
        "id": "gBXBhThG-cw5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "USE_CUDA = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "print(\"다음 기기로 학습합니다: \", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3KHJ6ue_3yB",
        "outputId": "737bf0bb-3235-49db-b06f-d2a463a2fc0a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "다음 기기로 학습합니다:  cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(777)\n",
        "torch.manual_seed(777)\n",
        "\n",
        "if device == 'cuda':\n",
        "  torch.cuda.manual_seed_all(777)"
      ],
      "metadata": {
        "id": "nfjeHkfZABiQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameter\n",
        "training_epochs = 10\n",
        "batch_size = 100\n",
        "\n",
        "\n",
        "# MNIST dataset\n",
        "train_dataset = dsets.MNIST(root='MNIST_data/',\n",
        "                          train=True,\n",
        "                          transform=transforms.ToTensor(),\n",
        "                          download=True)\n",
        "\n",
        "test_dataset = dsets.MNIST(root='MNIST_data/',\n",
        "                          train=False,\n",
        "                          transform=transforms.ToTensor(),\n",
        "                          download=True)\n",
        "\n",
        "\n",
        "# dataset loader\n",
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True,\n",
        "                          drop_last=True      # batch size에 data 개수가 딱 떨어지지 않으면 마지막 batch는 데이터 숫자가 적게 된다.\n",
        "                          )                   # 이때 그냥 적은 데이터 숫자로 학습을 진행하면 마지막 batch가 과대평가 될 수 있다.\n",
        "                                               # drop_last는 True를 할당하면 뒤의 남는 data를 그냥 버려준다.\n",
        "test_loader = DataLoader(dataset=test_dataset,\n",
        "                         batch_size=batch_size,\n",
        "                         shuffle=True\n",
        "                         )\n",
        "\n",
        "\n",
        "class MNIST_classification(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(784, 10, bias=True)   \n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.linear(x.view(-1, 784))\n",
        "\n",
        "\n",
        "model = MNIST_classification()\n",
        "model.to(device)   # 뒤의 to(device)는 gpu를 사용할 때 필요하다.\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "  model.train()    #train을 위한 형식\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    optimizer.zero_grad()     #학습을 완료할 때마다 gradient들을 0으로 초기화 해줘야 한다.\n",
        "    output = model(data)      #output 계산\n",
        "    loss = criterion(output, target)     #loss 계산\n",
        "    loss.backward()     #편미분 값 계산\n",
        "    optimizer.step()     #weight update\n",
        "\n",
        "    if batch_idx % 10 == 0:\n",
        "      print('Train Epoch : {} | Batch Status : {}/{} ({:.0f}%) | Loss : {:.6f}'.format(\n",
        "          epoch, batch_idx*len(data), len(train_loader.dataset),\n",
        "          100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "\n",
        "def test():\n",
        "  model.eval()    #test를 위한 형식\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "\n",
        "  for data, target in test_loader:      #답을 모를땐 target 부분이 존재하지 않는다. MNIST의 경우 답이 존재하므로 답 체크를 위해 써놓는 것\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    output = model(data)\n",
        "\n",
        "    # sum up batch loss\n",
        "    test_loss += criterion(output, target).item()     # loss.item()은 loss 스칼라 값을 준다.\n",
        "\n",
        "    # get the index of the max\n",
        "    # output.data는 100 x 10 즉 100개의 data들에 대한 0~9까지에 대한 확률 값인 1x10이고\n",
        "    # max(1, keepdim=True) 첫번째 인자가 1인 것은 0~9 중 무엇이 가장 큰지 찾으라는 것이고 \n",
        "    # 두번째 인자는 차원 유지 즉 100 x 1로 유지해준다. False로 하면 그냥 100됨\n",
        "    # max는 (value, index)를 반환하는데 여기다가 [1]을 했으므로 index를 찾게 된다. 즉 예측 label을 찾은 것이다.\n",
        "    pred = output.data.max(1, keepdim=True)[1]      \n",
        "\n",
        "    # .eq()를 통하여 예측값과 traget이 같은 지 계산해줍니다.\n",
        "    # target.data.view_as(pred) 모양을 바꿔 target을 pred랑 똑같은 차원이 되도록 한다.\n",
        "    # 한 batch 당 100개의 image가 나오는데 100 x 1의 tensor에다가 예측 label이 target과 같으면 1 아니면 0을 부여하므로 sum()을 하면 맞춘 횟수가 된다.\n",
        "    correct +=  pred.eq(target.data.view_as(pred)).cpu().sum()    \n",
        "\n",
        "    # 즉 correct는 총 맞춘 횟수이다.\n",
        "\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "  print(f'==================\\nTest set: Average loss : {test_loss:.4f}, Accuracy : {correct}/{len(test_loader.dataset)}'\n",
        "        f'({100. * correct / len(test_loader.dataset):.0f}%)')\n",
        " \n",
        "\n",
        "\n",
        "## Main\n",
        "\n",
        "if __name__ == '__main__':\n",
        " \n",
        "  since = time.time()\n",
        "  for epoch in range(1, training_epochs + 1):\n",
        "    epoch_start = time.time()\n",
        "    train(epoch)\n",
        "    m, s = divmod(time.time() - epoch_start, 60)\n",
        "    print(f'Training time: {m:.0f}m {s:.0f}s')\n",
        "    \n",
        "    test()\n",
        "    m, s = divmod(time.time() - epoch_start, 60)\n",
        "    print(f'Tesing time: {m:.0f}m {s:.0f}s')\n",
        "\n",
        "  m, s = divmod(time.time() - epoch_start, 60)\n",
        "  print(f'Total time : {m:.0f}m {s: .0f}s \\nModel was trained on {device}!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OpaFSI9ASIs",
        "outputId": "bc259099-d777-4478-ca9b-6002a9038fce"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch : 1 | Batch Status : 0/60000 (0%) | Loss : 2.330015\n",
            "Train Epoch : 1 | Batch Status : 1000/60000 (2%) | Loss : 1.595296\n",
            "Train Epoch : 1 | Batch Status : 2000/60000 (3%) | Loss : 1.253153\n",
            "Train Epoch : 1 | Batch Status : 3000/60000 (5%) | Loss : 1.005576\n",
            "Train Epoch : 1 | Batch Status : 4000/60000 (7%) | Loss : 0.837487\n",
            "Train Epoch : 1 | Batch Status : 5000/60000 (8%) | Loss : 0.883809\n",
            "Train Epoch : 1 | Batch Status : 6000/60000 (10%) | Loss : 0.758899\n",
            "Train Epoch : 1 | Batch Status : 7000/60000 (12%) | Loss : 0.681512\n",
            "Train Epoch : 1 | Batch Status : 8000/60000 (13%) | Loss : 0.644894\n",
            "Train Epoch : 1 | Batch Status : 9000/60000 (15%) | Loss : 0.683423\n",
            "Train Epoch : 1 | Batch Status : 10000/60000 (17%) | Loss : 0.571650\n",
            "Train Epoch : 1 | Batch Status : 11000/60000 (18%) | Loss : 0.635151\n",
            "Train Epoch : 1 | Batch Status : 12000/60000 (20%) | Loss : 0.563257\n",
            "Train Epoch : 1 | Batch Status : 13000/60000 (22%) | Loss : 0.650273\n",
            "Train Epoch : 1 | Batch Status : 14000/60000 (23%) | Loss : 0.554264\n",
            "Train Epoch : 1 | Batch Status : 15000/60000 (25%) | Loss : 0.549861\n",
            "Train Epoch : 1 | Batch Status : 16000/60000 (27%) | Loss : 0.649058\n",
            "Train Epoch : 1 | Batch Status : 17000/60000 (28%) | Loss : 0.566550\n",
            "Train Epoch : 1 | Batch Status : 18000/60000 (30%) | Loss : 0.523017\n",
            "Train Epoch : 1 | Batch Status : 19000/60000 (32%) | Loss : 0.556142\n",
            "Train Epoch : 1 | Batch Status : 20000/60000 (33%) | Loss : 0.404328\n",
            "Train Epoch : 1 | Batch Status : 21000/60000 (35%) | Loss : 0.581653\n",
            "Train Epoch : 1 | Batch Status : 22000/60000 (37%) | Loss : 0.475004\n",
            "Train Epoch : 1 | Batch Status : 23000/60000 (38%) | Loss : 0.604786\n",
            "Train Epoch : 1 | Batch Status : 24000/60000 (40%) | Loss : 0.416985\n",
            "Train Epoch : 1 | Batch Status : 25000/60000 (42%) | Loss : 0.351183\n",
            "Train Epoch : 1 | Batch Status : 26000/60000 (43%) | Loss : 0.497868\n",
            "Train Epoch : 1 | Batch Status : 27000/60000 (45%) | Loss : 0.542852\n",
            "Train Epoch : 1 | Batch Status : 28000/60000 (47%) | Loss : 0.414137\n",
            "Train Epoch : 1 | Batch Status : 29000/60000 (48%) | Loss : 0.406458\n",
            "Train Epoch : 1 | Batch Status : 30000/60000 (50%) | Loss : 0.487168\n",
            "Train Epoch : 1 | Batch Status : 31000/60000 (52%) | Loss : 0.517970\n",
            "Train Epoch : 1 | Batch Status : 32000/60000 (53%) | Loss : 0.392800\n",
            "Train Epoch : 1 | Batch Status : 33000/60000 (55%) | Loss : 0.489111\n",
            "Train Epoch : 1 | Batch Status : 34000/60000 (57%) | Loss : 0.382719\n",
            "Train Epoch : 1 | Batch Status : 35000/60000 (58%) | Loss : 0.521513\n",
            "Train Epoch : 1 | Batch Status : 36000/60000 (60%) | Loss : 0.507509\n",
            "Train Epoch : 1 | Batch Status : 37000/60000 (62%) | Loss : 0.395439\n",
            "Train Epoch : 1 | Batch Status : 38000/60000 (63%) | Loss : 0.450591\n",
            "Train Epoch : 1 | Batch Status : 39000/60000 (65%) | Loss : 0.307326\n",
            "Train Epoch : 1 | Batch Status : 40000/60000 (67%) | Loss : 0.302713\n",
            "Train Epoch : 1 | Batch Status : 41000/60000 (68%) | Loss : 0.410102\n",
            "Train Epoch : 1 | Batch Status : 42000/60000 (70%) | Loss : 0.329428\n",
            "Train Epoch : 1 | Batch Status : 43000/60000 (72%) | Loss : 0.665648\n",
            "Train Epoch : 1 | Batch Status : 44000/60000 (73%) | Loss : 0.449440\n",
            "Train Epoch : 1 | Batch Status : 45000/60000 (75%) | Loss : 0.416138\n",
            "Train Epoch : 1 | Batch Status : 46000/60000 (77%) | Loss : 0.430028\n",
            "Train Epoch : 1 | Batch Status : 47000/60000 (78%) | Loss : 0.460420\n",
            "Train Epoch : 1 | Batch Status : 48000/60000 (80%) | Loss : 0.394519\n",
            "Train Epoch : 1 | Batch Status : 49000/60000 (82%) | Loss : 0.274298\n",
            "Train Epoch : 1 | Batch Status : 50000/60000 (83%) | Loss : 0.429404\n",
            "Train Epoch : 1 | Batch Status : 51000/60000 (85%) | Loss : 0.317952\n",
            "Train Epoch : 1 | Batch Status : 52000/60000 (87%) | Loss : 0.416336\n",
            "Train Epoch : 1 | Batch Status : 53000/60000 (88%) | Loss : 0.378935\n",
            "Train Epoch : 1 | Batch Status : 54000/60000 (90%) | Loss : 0.377200\n",
            "Train Epoch : 1 | Batch Status : 55000/60000 (92%) | Loss : 0.303410\n",
            "Train Epoch : 1 | Batch Status : 56000/60000 (93%) | Loss : 0.463486\n",
            "Train Epoch : 1 | Batch Status : 57000/60000 (95%) | Loss : 0.568767\n",
            "Train Epoch : 1 | Batch Status : 58000/60000 (97%) | Loss : 0.445684\n",
            "Train Epoch : 1 | Batch Status : 59000/60000 (98%) | Loss : 0.248332\n",
            "Training time: 0m 6s\n",
            "==================\n",
            "Test set: Average loss : 0.0036, Accuracy : 9025/10000(90%)\n",
            "Tesing time: 0m 7s\n",
            "Train Epoch : 2 | Batch Status : 0/60000 (0%) | Loss : 0.426298\n",
            "Train Epoch : 2 | Batch Status : 1000/60000 (2%) | Loss : 0.496749\n",
            "Train Epoch : 2 | Batch Status : 2000/60000 (3%) | Loss : 0.314812\n",
            "Train Epoch : 2 | Batch Status : 3000/60000 (5%) | Loss : 0.540522\n",
            "Train Epoch : 2 | Batch Status : 4000/60000 (7%) | Loss : 0.555898\n",
            "Train Epoch : 2 | Batch Status : 5000/60000 (8%) | Loss : 0.541226\n",
            "Train Epoch : 2 | Batch Status : 6000/60000 (10%) | Loss : 0.336084\n",
            "Train Epoch : 2 | Batch Status : 7000/60000 (12%) | Loss : 0.427666\n",
            "Train Epoch : 2 | Batch Status : 8000/60000 (13%) | Loss : 0.337532\n",
            "Train Epoch : 2 | Batch Status : 9000/60000 (15%) | Loss : 0.421817\n",
            "Train Epoch : 2 | Batch Status : 10000/60000 (17%) | Loss : 0.252672\n",
            "Train Epoch : 2 | Batch Status : 11000/60000 (18%) | Loss : 0.288252\n",
            "Train Epoch : 2 | Batch Status : 12000/60000 (20%) | Loss : 0.424927\n",
            "Train Epoch : 2 | Batch Status : 13000/60000 (22%) | Loss : 0.460989\n",
            "Train Epoch : 2 | Batch Status : 14000/60000 (23%) | Loss : 0.416687\n",
            "Train Epoch : 2 | Batch Status : 15000/60000 (25%) | Loss : 0.353842\n",
            "Train Epoch : 2 | Batch Status : 16000/60000 (27%) | Loss : 0.313275\n",
            "Train Epoch : 2 | Batch Status : 17000/60000 (28%) | Loss : 0.345776\n",
            "Train Epoch : 2 | Batch Status : 18000/60000 (30%) | Loss : 0.395358\n",
            "Train Epoch : 2 | Batch Status : 19000/60000 (32%) | Loss : 0.302420\n",
            "Train Epoch : 2 | Batch Status : 20000/60000 (33%) | Loss : 0.459002\n",
            "Train Epoch : 2 | Batch Status : 21000/60000 (35%) | Loss : 0.290612\n",
            "Train Epoch : 2 | Batch Status : 22000/60000 (37%) | Loss : 0.271884\n",
            "Train Epoch : 2 | Batch Status : 23000/60000 (38%) | Loss : 0.344827\n",
            "Train Epoch : 2 | Batch Status : 24000/60000 (40%) | Loss : 0.461523\n",
            "Train Epoch : 2 | Batch Status : 25000/60000 (42%) | Loss : 0.456322\n",
            "Train Epoch : 2 | Batch Status : 26000/60000 (43%) | Loss : 0.304017\n",
            "Train Epoch : 2 | Batch Status : 27000/60000 (45%) | Loss : 0.287140\n",
            "Train Epoch : 2 | Batch Status : 28000/60000 (47%) | Loss : 0.449572\n",
            "Train Epoch : 2 | Batch Status : 29000/60000 (48%) | Loss : 0.561558\n",
            "Train Epoch : 2 | Batch Status : 30000/60000 (50%) | Loss : 0.274209\n",
            "Train Epoch : 2 | Batch Status : 31000/60000 (52%) | Loss : 0.486721\n",
            "Train Epoch : 2 | Batch Status : 32000/60000 (53%) | Loss : 0.335599\n",
            "Train Epoch : 2 | Batch Status : 33000/60000 (55%) | Loss : 0.326797\n",
            "Train Epoch : 2 | Batch Status : 34000/60000 (57%) | Loss : 0.274396\n",
            "Train Epoch : 2 | Batch Status : 35000/60000 (58%) | Loss : 0.254349\n",
            "Train Epoch : 2 | Batch Status : 36000/60000 (60%) | Loss : 0.316257\n",
            "Train Epoch : 2 | Batch Status : 37000/60000 (62%) | Loss : 0.279324\n",
            "Train Epoch : 2 | Batch Status : 38000/60000 (63%) | Loss : 0.398175\n",
            "Train Epoch : 2 | Batch Status : 39000/60000 (65%) | Loss : 0.233912\n",
            "Train Epoch : 2 | Batch Status : 40000/60000 (67%) | Loss : 0.301092\n",
            "Train Epoch : 2 | Batch Status : 41000/60000 (68%) | Loss : 0.220774\n",
            "Train Epoch : 2 | Batch Status : 42000/60000 (70%) | Loss : 0.262305\n",
            "Train Epoch : 2 | Batch Status : 43000/60000 (72%) | Loss : 0.175702\n",
            "Train Epoch : 2 | Batch Status : 44000/60000 (73%) | Loss : 0.367503\n",
            "Train Epoch : 2 | Batch Status : 45000/60000 (75%) | Loss : 0.337282\n",
            "Train Epoch : 2 | Batch Status : 46000/60000 (77%) | Loss : 0.289768\n",
            "Train Epoch : 2 | Batch Status : 47000/60000 (78%) | Loss : 0.246640\n",
            "Train Epoch : 2 | Batch Status : 48000/60000 (80%) | Loss : 0.323679\n",
            "Train Epoch : 2 | Batch Status : 49000/60000 (82%) | Loss : 0.341720\n",
            "Train Epoch : 2 | Batch Status : 50000/60000 (83%) | Loss : 0.222897\n",
            "Train Epoch : 2 | Batch Status : 51000/60000 (85%) | Loss : 0.336516\n",
            "Train Epoch : 2 | Batch Status : 52000/60000 (87%) | Loss : 0.348384\n",
            "Train Epoch : 2 | Batch Status : 53000/60000 (88%) | Loss : 0.326479\n",
            "Train Epoch : 2 | Batch Status : 54000/60000 (90%) | Loss : 0.331386\n",
            "Train Epoch : 2 | Batch Status : 55000/60000 (92%) | Loss : 0.298611\n",
            "Train Epoch : 2 | Batch Status : 56000/60000 (93%) | Loss : 0.372990\n",
            "Train Epoch : 2 | Batch Status : 57000/60000 (95%) | Loss : 0.308212\n",
            "Train Epoch : 2 | Batch Status : 58000/60000 (97%) | Loss : 0.462206\n",
            "Train Epoch : 2 | Batch Status : 59000/60000 (98%) | Loss : 0.395572\n",
            "Training time: 0m 6s\n",
            "==================\n",
            "Test set: Average loss : 0.0032, Accuracy : 9104/10000(91%)\n",
            "Tesing time: 0m 7s\n",
            "Train Epoch : 3 | Batch Status : 0/60000 (0%) | Loss : 0.476365\n",
            "Train Epoch : 3 | Batch Status : 1000/60000 (2%) | Loss : 0.294667\n",
            "Train Epoch : 3 | Batch Status : 2000/60000 (3%) | Loss : 0.407926\n",
            "Train Epoch : 3 | Batch Status : 3000/60000 (5%) | Loss : 0.402528\n",
            "Train Epoch : 3 | Batch Status : 4000/60000 (7%) | Loss : 0.339400\n",
            "Train Epoch : 3 | Batch Status : 5000/60000 (8%) | Loss : 0.235299\n",
            "Train Epoch : 3 | Batch Status : 6000/60000 (10%) | Loss : 0.251865\n",
            "Train Epoch : 3 | Batch Status : 7000/60000 (12%) | Loss : 0.418688\n",
            "Train Epoch : 3 | Batch Status : 8000/60000 (13%) | Loss : 0.308085\n",
            "Train Epoch : 3 | Batch Status : 9000/60000 (15%) | Loss : 0.285375\n",
            "Train Epoch : 3 | Batch Status : 10000/60000 (17%) | Loss : 0.358679\n",
            "Train Epoch : 3 | Batch Status : 11000/60000 (18%) | Loss : 0.346252\n",
            "Train Epoch : 3 | Batch Status : 12000/60000 (20%) | Loss : 0.405276\n",
            "Train Epoch : 3 | Batch Status : 13000/60000 (22%) | Loss : 0.308967\n",
            "Train Epoch : 3 | Batch Status : 14000/60000 (23%) | Loss : 0.529826\n",
            "Train Epoch : 3 | Batch Status : 15000/60000 (25%) | Loss : 0.356921\n",
            "Train Epoch : 3 | Batch Status : 16000/60000 (27%) | Loss : 0.318247\n",
            "Train Epoch : 3 | Batch Status : 17000/60000 (28%) | Loss : 0.315733\n",
            "Train Epoch : 3 | Batch Status : 18000/60000 (30%) | Loss : 0.317356\n",
            "Train Epoch : 3 | Batch Status : 19000/60000 (32%) | Loss : 0.279138\n",
            "Train Epoch : 3 | Batch Status : 20000/60000 (33%) | Loss : 0.435136\n",
            "Train Epoch : 3 | Batch Status : 21000/60000 (35%) | Loss : 0.381290\n",
            "Train Epoch : 3 | Batch Status : 22000/60000 (37%) | Loss : 0.237921\n",
            "Train Epoch : 3 | Batch Status : 23000/60000 (38%) | Loss : 0.411405\n",
            "Train Epoch : 3 | Batch Status : 24000/60000 (40%) | Loss : 0.425316\n",
            "Train Epoch : 3 | Batch Status : 25000/60000 (42%) | Loss : 0.422519\n",
            "Train Epoch : 3 | Batch Status : 26000/60000 (43%) | Loss : 0.262997\n",
            "Train Epoch : 3 | Batch Status : 27000/60000 (45%) | Loss : 0.332550\n",
            "Train Epoch : 3 | Batch Status : 28000/60000 (47%) | Loss : 0.316609\n",
            "Train Epoch : 3 | Batch Status : 29000/60000 (48%) | Loss : 0.332680\n",
            "Train Epoch : 3 | Batch Status : 30000/60000 (50%) | Loss : 0.414830\n",
            "Train Epoch : 3 | Batch Status : 31000/60000 (52%) | Loss : 0.352490\n",
            "Train Epoch : 3 | Batch Status : 32000/60000 (53%) | Loss : 0.369981\n",
            "Train Epoch : 3 | Batch Status : 33000/60000 (55%) | Loss : 0.293820\n",
            "Train Epoch : 3 | Batch Status : 34000/60000 (57%) | Loss : 0.203625\n",
            "Train Epoch : 3 | Batch Status : 35000/60000 (58%) | Loss : 0.211500\n",
            "Train Epoch : 3 | Batch Status : 36000/60000 (60%) | Loss : 0.266924\n",
            "Train Epoch : 3 | Batch Status : 37000/60000 (62%) | Loss : 0.384952\n",
            "Train Epoch : 3 | Batch Status : 38000/60000 (63%) | Loss : 0.257076\n",
            "Train Epoch : 3 | Batch Status : 39000/60000 (65%) | Loss : 0.188883\n",
            "Train Epoch : 3 | Batch Status : 40000/60000 (67%) | Loss : 0.144977\n",
            "Train Epoch : 3 | Batch Status : 41000/60000 (68%) | Loss : 0.487718\n",
            "Train Epoch : 3 | Batch Status : 42000/60000 (70%) | Loss : 0.264219\n",
            "Train Epoch : 3 | Batch Status : 43000/60000 (72%) | Loss : 0.437735\n",
            "Train Epoch : 3 | Batch Status : 44000/60000 (73%) | Loss : 0.343311\n",
            "Train Epoch : 3 | Batch Status : 45000/60000 (75%) | Loss : 0.390405\n",
            "Train Epoch : 3 | Batch Status : 46000/60000 (77%) | Loss : 0.272217\n",
            "Train Epoch : 3 | Batch Status : 47000/60000 (78%) | Loss : 0.451222\n",
            "Train Epoch : 3 | Batch Status : 48000/60000 (80%) | Loss : 0.234323\n",
            "Train Epoch : 3 | Batch Status : 49000/60000 (82%) | Loss : 0.264740\n",
            "Train Epoch : 3 | Batch Status : 50000/60000 (83%) | Loss : 0.305665\n",
            "Train Epoch : 3 | Batch Status : 51000/60000 (85%) | Loss : 0.356133\n",
            "Train Epoch : 3 | Batch Status : 52000/60000 (87%) | Loss : 0.232390\n",
            "Train Epoch : 3 | Batch Status : 53000/60000 (88%) | Loss : 0.360002\n",
            "Train Epoch : 3 | Batch Status : 54000/60000 (90%) | Loss : 0.202435\n",
            "Train Epoch : 3 | Batch Status : 55000/60000 (92%) | Loss : 0.265239\n",
            "Train Epoch : 3 | Batch Status : 56000/60000 (93%) | Loss : 0.237637\n",
            "Train Epoch : 3 | Batch Status : 57000/60000 (95%) | Loss : 0.265039\n",
            "Train Epoch : 3 | Batch Status : 58000/60000 (97%) | Loss : 0.424635\n",
            "Train Epoch : 3 | Batch Status : 59000/60000 (98%) | Loss : 0.187092\n",
            "Training time: 0m 6s\n",
            "==================\n",
            "Test set: Average loss : 0.0031, Accuracy : 9159/10000(92%)\n",
            "Tesing time: 0m 7s\n",
            "Train Epoch : 4 | Batch Status : 0/60000 (0%) | Loss : 0.310832\n",
            "Train Epoch : 4 | Batch Status : 1000/60000 (2%) | Loss : 0.293036\n",
            "Train Epoch : 4 | Batch Status : 2000/60000 (3%) | Loss : 0.245681\n",
            "Train Epoch : 4 | Batch Status : 3000/60000 (5%) | Loss : 0.476320\n",
            "Train Epoch : 4 | Batch Status : 4000/60000 (7%) | Loss : 0.216962\n",
            "Train Epoch : 4 | Batch Status : 5000/60000 (8%) | Loss : 0.381031\n",
            "Train Epoch : 4 | Batch Status : 6000/60000 (10%) | Loss : 0.256906\n",
            "Train Epoch : 4 | Batch Status : 7000/60000 (12%) | Loss : 0.254420\n",
            "Train Epoch : 4 | Batch Status : 8000/60000 (13%) | Loss : 0.347194\n",
            "Train Epoch : 4 | Batch Status : 9000/60000 (15%) | Loss : 0.283170\n",
            "Train Epoch : 4 | Batch Status : 10000/60000 (17%) | Loss : 0.349410\n",
            "Train Epoch : 4 | Batch Status : 11000/60000 (18%) | Loss : 0.317673\n",
            "Train Epoch : 4 | Batch Status : 12000/60000 (20%) | Loss : 0.316559\n",
            "Train Epoch : 4 | Batch Status : 13000/60000 (22%) | Loss : 0.435060\n",
            "Train Epoch : 4 | Batch Status : 14000/60000 (23%) | Loss : 0.345854\n",
            "Train Epoch : 4 | Batch Status : 15000/60000 (25%) | Loss : 0.176767\n",
            "Train Epoch : 4 | Batch Status : 16000/60000 (27%) | Loss : 0.235198\n",
            "Train Epoch : 4 | Batch Status : 17000/60000 (28%) | Loss : 0.328901\n",
            "Train Epoch : 4 | Batch Status : 18000/60000 (30%) | Loss : 0.305808\n",
            "Train Epoch : 4 | Batch Status : 19000/60000 (32%) | Loss : 0.406431\n",
            "Train Epoch : 4 | Batch Status : 20000/60000 (33%) | Loss : 0.350975\n",
            "Train Epoch : 4 | Batch Status : 21000/60000 (35%) | Loss : 0.361590\n",
            "Train Epoch : 4 | Batch Status : 22000/60000 (37%) | Loss : 0.259461\n",
            "Train Epoch : 4 | Batch Status : 23000/60000 (38%) | Loss : 0.268537\n",
            "Train Epoch : 4 | Batch Status : 24000/60000 (40%) | Loss : 0.235869\n",
            "Train Epoch : 4 | Batch Status : 25000/60000 (42%) | Loss : 0.288058\n",
            "Train Epoch : 4 | Batch Status : 26000/60000 (43%) | Loss : 0.522344\n",
            "Train Epoch : 4 | Batch Status : 27000/60000 (45%) | Loss : 0.282759\n",
            "Train Epoch : 4 | Batch Status : 28000/60000 (47%) | Loss : 0.321434\n",
            "Train Epoch : 4 | Batch Status : 29000/60000 (48%) | Loss : 0.244971\n",
            "Train Epoch : 4 | Batch Status : 30000/60000 (50%) | Loss : 0.350323\n",
            "Train Epoch : 4 | Batch Status : 31000/60000 (52%) | Loss : 0.239581\n",
            "Train Epoch : 4 | Batch Status : 32000/60000 (53%) | Loss : 0.286424\n",
            "Train Epoch : 4 | Batch Status : 33000/60000 (55%) | Loss : 0.395046\n",
            "Train Epoch : 4 | Batch Status : 34000/60000 (57%) | Loss : 0.358309\n",
            "Train Epoch : 4 | Batch Status : 35000/60000 (58%) | Loss : 0.369983\n",
            "Train Epoch : 4 | Batch Status : 36000/60000 (60%) | Loss : 0.213547\n",
            "Train Epoch : 4 | Batch Status : 37000/60000 (62%) | Loss : 0.250854\n",
            "Train Epoch : 4 | Batch Status : 38000/60000 (63%) | Loss : 0.312585\n",
            "Train Epoch : 4 | Batch Status : 39000/60000 (65%) | Loss : 0.308495\n",
            "Train Epoch : 4 | Batch Status : 40000/60000 (67%) | Loss : 0.142649\n",
            "Train Epoch : 4 | Batch Status : 41000/60000 (68%) | Loss : 0.319057\n",
            "Train Epoch : 4 | Batch Status : 42000/60000 (70%) | Loss : 0.198261\n",
            "Train Epoch : 4 | Batch Status : 43000/60000 (72%) | Loss : 0.371534\n",
            "Train Epoch : 4 | Batch Status : 44000/60000 (73%) | Loss : 0.385789\n",
            "Train Epoch : 4 | Batch Status : 45000/60000 (75%) | Loss : 0.423415\n",
            "Train Epoch : 4 | Batch Status : 46000/60000 (77%) | Loss : 0.416788\n",
            "Train Epoch : 4 | Batch Status : 47000/60000 (78%) | Loss : 0.319943\n",
            "Train Epoch : 4 | Batch Status : 48000/60000 (80%) | Loss : 0.375697\n",
            "Train Epoch : 4 | Batch Status : 49000/60000 (82%) | Loss : 0.259172\n",
            "Train Epoch : 4 | Batch Status : 50000/60000 (83%) | Loss : 0.235383\n",
            "Train Epoch : 4 | Batch Status : 51000/60000 (85%) | Loss : 0.272474\n",
            "Train Epoch : 4 | Batch Status : 52000/60000 (87%) | Loss : 0.253524\n",
            "Train Epoch : 4 | Batch Status : 53000/60000 (88%) | Loss : 0.255562\n",
            "Train Epoch : 4 | Batch Status : 54000/60000 (90%) | Loss : 0.392203\n",
            "Train Epoch : 4 | Batch Status : 55000/60000 (92%) | Loss : 0.178339\n",
            "Train Epoch : 4 | Batch Status : 56000/60000 (93%) | Loss : 0.281318\n",
            "Train Epoch : 4 | Batch Status : 57000/60000 (95%) | Loss : 0.303266\n",
            "Train Epoch : 4 | Batch Status : 58000/60000 (97%) | Loss : 0.263044\n",
            "Train Epoch : 4 | Batch Status : 59000/60000 (98%) | Loss : 0.291452\n",
            "Training time: 0m 6s\n",
            "==================\n",
            "Test set: Average loss : 0.0030, Accuracy : 9177/10000(92%)\n",
            "Tesing time: 0m 7s\n",
            "Train Epoch : 5 | Batch Status : 0/60000 (0%) | Loss : 0.347464\n",
            "Train Epoch : 5 | Batch Status : 1000/60000 (2%) | Loss : 0.201877\n",
            "Train Epoch : 5 | Batch Status : 2000/60000 (3%) | Loss : 0.278974\n",
            "Train Epoch : 5 | Batch Status : 3000/60000 (5%) | Loss : 0.211097\n",
            "Train Epoch : 5 | Batch Status : 4000/60000 (7%) | Loss : 0.223443\n",
            "Train Epoch : 5 | Batch Status : 5000/60000 (8%) | Loss : 0.452370\n",
            "Train Epoch : 5 | Batch Status : 6000/60000 (10%) | Loss : 0.219136\n",
            "Train Epoch : 5 | Batch Status : 7000/60000 (12%) | Loss : 0.282454\n",
            "Train Epoch : 5 | Batch Status : 8000/60000 (13%) | Loss : 0.310841\n",
            "Train Epoch : 5 | Batch Status : 9000/60000 (15%) | Loss : 0.277932\n",
            "Train Epoch : 5 | Batch Status : 10000/60000 (17%) | Loss : 0.367012\n",
            "Train Epoch : 5 | Batch Status : 11000/60000 (18%) | Loss : 0.179840\n",
            "Train Epoch : 5 | Batch Status : 12000/60000 (20%) | Loss : 0.359829\n",
            "Train Epoch : 5 | Batch Status : 13000/60000 (22%) | Loss : 0.304268\n",
            "Train Epoch : 5 | Batch Status : 14000/60000 (23%) | Loss : 0.308095\n",
            "Train Epoch : 5 | Batch Status : 15000/60000 (25%) | Loss : 0.360434\n",
            "Train Epoch : 5 | Batch Status : 16000/60000 (27%) | Loss : 0.283339\n",
            "Train Epoch : 5 | Batch Status : 17000/60000 (28%) | Loss : 0.262362\n",
            "Train Epoch : 5 | Batch Status : 18000/60000 (30%) | Loss : 0.122406\n",
            "Train Epoch : 5 | Batch Status : 19000/60000 (32%) | Loss : 0.226524\n",
            "Train Epoch : 5 | Batch Status : 20000/60000 (33%) | Loss : 0.346822\n",
            "Train Epoch : 5 | Batch Status : 21000/60000 (35%) | Loss : 0.303715\n",
            "Train Epoch : 5 | Batch Status : 22000/60000 (37%) | Loss : 0.212778\n",
            "Train Epoch : 5 | Batch Status : 23000/60000 (38%) | Loss : 0.307561\n",
            "Train Epoch : 5 | Batch Status : 24000/60000 (40%) | Loss : 0.253967\n",
            "Train Epoch : 5 | Batch Status : 25000/60000 (42%) | Loss : 0.392361\n",
            "Train Epoch : 5 | Batch Status : 26000/60000 (43%) | Loss : 0.505629\n",
            "Train Epoch : 5 | Batch Status : 27000/60000 (45%) | Loss : 0.163474\n",
            "Train Epoch : 5 | Batch Status : 28000/60000 (47%) | Loss : 0.382527\n",
            "Train Epoch : 5 | Batch Status : 29000/60000 (48%) | Loss : 0.240148\n",
            "Train Epoch : 5 | Batch Status : 30000/60000 (50%) | Loss : 0.340141\n",
            "Train Epoch : 5 | Batch Status : 31000/60000 (52%) | Loss : 0.257239\n",
            "Train Epoch : 5 | Batch Status : 32000/60000 (53%) | Loss : 0.325310\n",
            "Train Epoch : 5 | Batch Status : 33000/60000 (55%) | Loss : 0.348149\n",
            "Train Epoch : 5 | Batch Status : 34000/60000 (57%) | Loss : 0.311284\n",
            "Train Epoch : 5 | Batch Status : 35000/60000 (58%) | Loss : 0.418124\n",
            "Train Epoch : 5 | Batch Status : 36000/60000 (60%) | Loss : 0.318288\n",
            "Train Epoch : 5 | Batch Status : 37000/60000 (62%) | Loss : 0.225897\n",
            "Train Epoch : 5 | Batch Status : 38000/60000 (63%) | Loss : 0.381177\n",
            "Train Epoch : 5 | Batch Status : 39000/60000 (65%) | Loss : 0.303064\n",
            "Train Epoch : 5 | Batch Status : 40000/60000 (67%) | Loss : 0.204517\n",
            "Train Epoch : 5 | Batch Status : 41000/60000 (68%) | Loss : 0.254963\n",
            "Train Epoch : 5 | Batch Status : 42000/60000 (70%) | Loss : 0.224022\n",
            "Train Epoch : 5 | Batch Status : 43000/60000 (72%) | Loss : 0.223236\n",
            "Train Epoch : 5 | Batch Status : 44000/60000 (73%) | Loss : 0.311177\n",
            "Train Epoch : 5 | Batch Status : 45000/60000 (75%) | Loss : 0.417092\n",
            "Train Epoch : 5 | Batch Status : 46000/60000 (77%) | Loss : 0.355049\n",
            "Train Epoch : 5 | Batch Status : 47000/60000 (78%) | Loss : 0.285211\n",
            "Train Epoch : 5 | Batch Status : 48000/60000 (80%) | Loss : 0.186243\n",
            "Train Epoch : 5 | Batch Status : 49000/60000 (82%) | Loss : 0.390549\n",
            "Train Epoch : 5 | Batch Status : 50000/60000 (83%) | Loss : 0.239713\n",
            "Train Epoch : 5 | Batch Status : 51000/60000 (85%) | Loss : 0.244904\n",
            "Train Epoch : 5 | Batch Status : 52000/60000 (87%) | Loss : 0.362299\n",
            "Train Epoch : 5 | Batch Status : 53000/60000 (88%) | Loss : 0.396789\n",
            "Train Epoch : 5 | Batch Status : 54000/60000 (90%) | Loss : 0.381646\n",
            "Train Epoch : 5 | Batch Status : 55000/60000 (92%) | Loss : 0.266656\n",
            "Train Epoch : 5 | Batch Status : 56000/60000 (93%) | Loss : 0.247981\n",
            "Train Epoch : 5 | Batch Status : 57000/60000 (95%) | Loss : 0.320300\n",
            "Train Epoch : 5 | Batch Status : 58000/60000 (97%) | Loss : 0.463062\n",
            "Train Epoch : 5 | Batch Status : 59000/60000 (98%) | Loss : 0.363762\n",
            "Training time: 0m 6s\n",
            "==================\n",
            "Test set: Average loss : 0.0029, Accuracy : 9177/10000(92%)\n",
            "Tesing time: 0m 7s\n",
            "Train Epoch : 6 | Batch Status : 0/60000 (0%) | Loss : 0.403857\n",
            "Train Epoch : 6 | Batch Status : 1000/60000 (2%) | Loss : 0.394157\n",
            "Train Epoch : 6 | Batch Status : 2000/60000 (3%) | Loss : 0.228014\n",
            "Train Epoch : 6 | Batch Status : 3000/60000 (5%) | Loss : 0.405214\n",
            "Train Epoch : 6 | Batch Status : 4000/60000 (7%) | Loss : 0.320608\n",
            "Train Epoch : 6 | Batch Status : 5000/60000 (8%) | Loss : 0.244595\n",
            "Train Epoch : 6 | Batch Status : 6000/60000 (10%) | Loss : 0.341437\n",
            "Train Epoch : 6 | Batch Status : 7000/60000 (12%) | Loss : 0.263140\n",
            "Train Epoch : 6 | Batch Status : 8000/60000 (13%) | Loss : 0.298190\n",
            "Train Epoch : 6 | Batch Status : 9000/60000 (15%) | Loss : 0.273267\n",
            "Train Epoch : 6 | Batch Status : 10000/60000 (17%) | Loss : 0.339985\n",
            "Train Epoch : 6 | Batch Status : 11000/60000 (18%) | Loss : 0.248455\n",
            "Train Epoch : 6 | Batch Status : 12000/60000 (20%) | Loss : 0.283412\n",
            "Train Epoch : 6 | Batch Status : 13000/60000 (22%) | Loss : 0.389383\n",
            "Train Epoch : 6 | Batch Status : 14000/60000 (23%) | Loss : 0.344639\n",
            "Train Epoch : 6 | Batch Status : 15000/60000 (25%) | Loss : 0.357618\n",
            "Train Epoch : 6 | Batch Status : 16000/60000 (27%) | Loss : 0.386163\n",
            "Train Epoch : 6 | Batch Status : 17000/60000 (28%) | Loss : 0.352475\n",
            "Train Epoch : 6 | Batch Status : 18000/60000 (30%) | Loss : 0.169101\n",
            "Train Epoch : 6 | Batch Status : 19000/60000 (32%) | Loss : 0.389237\n",
            "Train Epoch : 6 | Batch Status : 20000/60000 (33%) | Loss : 0.344238\n",
            "Train Epoch : 6 | Batch Status : 21000/60000 (35%) | Loss : 0.316673\n",
            "Train Epoch : 6 | Batch Status : 22000/60000 (37%) | Loss : 0.363638\n",
            "Train Epoch : 6 | Batch Status : 23000/60000 (38%) | Loss : 0.185814\n",
            "Train Epoch : 6 | Batch Status : 24000/60000 (40%) | Loss : 0.348315\n",
            "Train Epoch : 6 | Batch Status : 25000/60000 (42%) | Loss : 0.200095\n",
            "Train Epoch : 6 | Batch Status : 26000/60000 (43%) | Loss : 0.268400\n",
            "Train Epoch : 6 | Batch Status : 27000/60000 (45%) | Loss : 0.325087\n",
            "Train Epoch : 6 | Batch Status : 28000/60000 (47%) | Loss : 0.387029\n",
            "Train Epoch : 6 | Batch Status : 29000/60000 (48%) | Loss : 0.210012\n",
            "Train Epoch : 6 | Batch Status : 30000/60000 (50%) | Loss : 0.358535\n",
            "Train Epoch : 6 | Batch Status : 31000/60000 (52%) | Loss : 0.145697\n",
            "Train Epoch : 6 | Batch Status : 32000/60000 (53%) | Loss : 0.335146\n",
            "Train Epoch : 6 | Batch Status : 33000/60000 (55%) | Loss : 0.331250\n",
            "Train Epoch : 6 | Batch Status : 34000/60000 (57%) | Loss : 0.230199\n",
            "Train Epoch : 6 | Batch Status : 35000/60000 (58%) | Loss : 0.221743\n",
            "Train Epoch : 6 | Batch Status : 36000/60000 (60%) | Loss : 0.204032\n",
            "Train Epoch : 6 | Batch Status : 37000/60000 (62%) | Loss : 0.321375\n",
            "Train Epoch : 6 | Batch Status : 38000/60000 (63%) | Loss : 0.283052\n",
            "Train Epoch : 6 | Batch Status : 39000/60000 (65%) | Loss : 0.419760\n",
            "Train Epoch : 6 | Batch Status : 40000/60000 (67%) | Loss : 0.369912\n",
            "Train Epoch : 6 | Batch Status : 41000/60000 (68%) | Loss : 0.209063\n",
            "Train Epoch : 6 | Batch Status : 42000/60000 (70%) | Loss : 0.216006\n",
            "Train Epoch : 6 | Batch Status : 43000/60000 (72%) | Loss : 0.325399\n",
            "Train Epoch : 6 | Batch Status : 44000/60000 (73%) | Loss : 0.333817\n",
            "Train Epoch : 6 | Batch Status : 45000/60000 (75%) | Loss : 0.296319\n",
            "Train Epoch : 6 | Batch Status : 46000/60000 (77%) | Loss : 0.284411\n",
            "Train Epoch : 6 | Batch Status : 47000/60000 (78%) | Loss : 0.192703\n",
            "Train Epoch : 6 | Batch Status : 48000/60000 (80%) | Loss : 0.322845\n",
            "Train Epoch : 6 | Batch Status : 49000/60000 (82%) | Loss : 0.279091\n",
            "Train Epoch : 6 | Batch Status : 50000/60000 (83%) | Loss : 0.476781\n",
            "Train Epoch : 6 | Batch Status : 51000/60000 (85%) | Loss : 0.316077\n",
            "Train Epoch : 6 | Batch Status : 52000/60000 (87%) | Loss : 0.405465\n",
            "Train Epoch : 6 | Batch Status : 53000/60000 (88%) | Loss : 0.282462\n",
            "Train Epoch : 6 | Batch Status : 54000/60000 (90%) | Loss : 0.218316\n",
            "Train Epoch : 6 | Batch Status : 55000/60000 (92%) | Loss : 0.225697\n",
            "Train Epoch : 6 | Batch Status : 56000/60000 (93%) | Loss : 0.354572\n",
            "Train Epoch : 6 | Batch Status : 57000/60000 (95%) | Loss : 0.242970\n",
            "Train Epoch : 6 | Batch Status : 58000/60000 (97%) | Loss : 0.291474\n",
            "Train Epoch : 6 | Batch Status : 59000/60000 (98%) | Loss : 0.324912\n",
            "Training time: 0m 6s\n",
            "==================\n",
            "Test set: Average loss : 0.0029, Accuracy : 9196/10000(92%)\n",
            "Tesing time: 0m 7s\n",
            "Train Epoch : 7 | Batch Status : 0/60000 (0%) | Loss : 0.381439\n",
            "Train Epoch : 7 | Batch Status : 1000/60000 (2%) | Loss : 0.235406\n",
            "Train Epoch : 7 | Batch Status : 2000/60000 (3%) | Loss : 0.306828\n",
            "Train Epoch : 7 | Batch Status : 3000/60000 (5%) | Loss : 0.278633\n",
            "Train Epoch : 7 | Batch Status : 4000/60000 (7%) | Loss : 0.256689\n",
            "Train Epoch : 7 | Batch Status : 5000/60000 (8%) | Loss : 0.234496\n",
            "Train Epoch : 7 | Batch Status : 6000/60000 (10%) | Loss : 0.150594\n",
            "Train Epoch : 7 | Batch Status : 7000/60000 (12%) | Loss : 0.367516\n",
            "Train Epoch : 7 | Batch Status : 8000/60000 (13%) | Loss : 0.261601\n",
            "Train Epoch : 7 | Batch Status : 9000/60000 (15%) | Loss : 0.229041\n",
            "Train Epoch : 7 | Batch Status : 10000/60000 (17%) | Loss : 0.242971\n",
            "Train Epoch : 7 | Batch Status : 11000/60000 (18%) | Loss : 0.346031\n",
            "Train Epoch : 7 | Batch Status : 12000/60000 (20%) | Loss : 0.317665\n",
            "Train Epoch : 7 | Batch Status : 13000/60000 (22%) | Loss : 0.353384\n",
            "Train Epoch : 7 | Batch Status : 14000/60000 (23%) | Loss : 0.369625\n",
            "Train Epoch : 7 | Batch Status : 15000/60000 (25%) | Loss : 0.299833\n",
            "Train Epoch : 7 | Batch Status : 16000/60000 (27%) | Loss : 0.293235\n",
            "Train Epoch : 7 | Batch Status : 17000/60000 (28%) | Loss : 0.277789\n",
            "Train Epoch : 7 | Batch Status : 18000/60000 (30%) | Loss : 0.357026\n",
            "Train Epoch : 7 | Batch Status : 19000/60000 (32%) | Loss : 0.391144\n",
            "Train Epoch : 7 | Batch Status : 20000/60000 (33%) | Loss : 0.356963\n",
            "Train Epoch : 7 | Batch Status : 21000/60000 (35%) | Loss : 0.218212\n",
            "Train Epoch : 7 | Batch Status : 22000/60000 (37%) | Loss : 0.163213\n",
            "Train Epoch : 7 | Batch Status : 23000/60000 (38%) | Loss : 0.301417\n",
            "Train Epoch : 7 | Batch Status : 24000/60000 (40%) | Loss : 0.191408\n",
            "Train Epoch : 7 | Batch Status : 25000/60000 (42%) | Loss : 0.220334\n",
            "Train Epoch : 7 | Batch Status : 26000/60000 (43%) | Loss : 0.386207\n",
            "Train Epoch : 7 | Batch Status : 27000/60000 (45%) | Loss : 0.343652\n",
            "Train Epoch : 7 | Batch Status : 28000/60000 (47%) | Loss : 0.353461\n",
            "Train Epoch : 7 | Batch Status : 29000/60000 (48%) | Loss : 0.304726\n",
            "Train Epoch : 7 | Batch Status : 30000/60000 (50%) | Loss : 0.235224\n",
            "Train Epoch : 7 | Batch Status : 31000/60000 (52%) | Loss : 0.275254\n",
            "Train Epoch : 7 | Batch Status : 32000/60000 (53%) | Loss : 0.300008\n",
            "Train Epoch : 7 | Batch Status : 33000/60000 (55%) | Loss : 0.201376\n",
            "Train Epoch : 7 | Batch Status : 34000/60000 (57%) | Loss : 0.336644\n",
            "Train Epoch : 7 | Batch Status : 35000/60000 (58%) | Loss : 0.440397\n",
            "Train Epoch : 7 | Batch Status : 36000/60000 (60%) | Loss : 0.317722\n",
            "Train Epoch : 7 | Batch Status : 37000/60000 (62%) | Loss : 0.262334\n",
            "Train Epoch : 7 | Batch Status : 38000/60000 (63%) | Loss : 0.249712\n",
            "Train Epoch : 7 | Batch Status : 39000/60000 (65%) | Loss : 0.285952\n",
            "Train Epoch : 7 | Batch Status : 40000/60000 (67%) | Loss : 0.265140\n",
            "Train Epoch : 7 | Batch Status : 41000/60000 (68%) | Loss : 0.272749\n",
            "Train Epoch : 7 | Batch Status : 42000/60000 (70%) | Loss : 0.287083\n",
            "Train Epoch : 7 | Batch Status : 43000/60000 (72%) | Loss : 0.251384\n",
            "Train Epoch : 7 | Batch Status : 44000/60000 (73%) | Loss : 0.260013\n",
            "Train Epoch : 7 | Batch Status : 45000/60000 (75%) | Loss : 0.438104\n",
            "Train Epoch : 7 | Batch Status : 46000/60000 (77%) | Loss : 0.521558\n",
            "Train Epoch : 7 | Batch Status : 47000/60000 (78%) | Loss : 0.231000\n",
            "Train Epoch : 7 | Batch Status : 48000/60000 (80%) | Loss : 0.281506\n",
            "Train Epoch : 7 | Batch Status : 49000/60000 (82%) | Loss : 0.503514\n",
            "Train Epoch : 7 | Batch Status : 50000/60000 (83%) | Loss : 0.370390\n",
            "Train Epoch : 7 | Batch Status : 51000/60000 (85%) | Loss : 0.228462\n",
            "Train Epoch : 7 | Batch Status : 52000/60000 (87%) | Loss : 0.390463\n",
            "Train Epoch : 7 | Batch Status : 53000/60000 (88%) | Loss : 0.363467\n",
            "Train Epoch : 7 | Batch Status : 54000/60000 (90%) | Loss : 0.265778\n",
            "Train Epoch : 7 | Batch Status : 55000/60000 (92%) | Loss : 0.315725\n",
            "Train Epoch : 7 | Batch Status : 56000/60000 (93%) | Loss : 0.331342\n",
            "Train Epoch : 7 | Batch Status : 57000/60000 (95%) | Loss : 0.341048\n",
            "Train Epoch : 7 | Batch Status : 58000/60000 (97%) | Loss : 0.244035\n",
            "Train Epoch : 7 | Batch Status : 59000/60000 (98%) | Loss : 0.352731\n",
            "Training time: 0m 6s\n",
            "==================\n",
            "Test set: Average loss : 0.0029, Accuracy : 9202/10000(92%)\n",
            "Tesing time: 0m 7s\n",
            "Train Epoch : 8 | Batch Status : 0/60000 (0%) | Loss : 0.516041\n",
            "Train Epoch : 8 | Batch Status : 1000/60000 (2%) | Loss : 0.406027\n",
            "Train Epoch : 8 | Batch Status : 2000/60000 (3%) | Loss : 0.293467\n",
            "Train Epoch : 8 | Batch Status : 3000/60000 (5%) | Loss : 0.281314\n",
            "Train Epoch : 8 | Batch Status : 4000/60000 (7%) | Loss : 0.356327\n",
            "Train Epoch : 8 | Batch Status : 5000/60000 (8%) | Loss : 0.238534\n",
            "Train Epoch : 8 | Batch Status : 6000/60000 (10%) | Loss : 0.232802\n",
            "Train Epoch : 8 | Batch Status : 7000/60000 (12%) | Loss : 0.386909\n",
            "Train Epoch : 8 | Batch Status : 8000/60000 (13%) | Loss : 0.367843\n",
            "Train Epoch : 8 | Batch Status : 9000/60000 (15%) | Loss : 0.285925\n",
            "Train Epoch : 8 | Batch Status : 10000/60000 (17%) | Loss : 0.255853\n",
            "Train Epoch : 8 | Batch Status : 11000/60000 (18%) | Loss : 0.220578\n",
            "Train Epoch : 8 | Batch Status : 12000/60000 (20%) | Loss : 0.250497\n",
            "Train Epoch : 8 | Batch Status : 13000/60000 (22%) | Loss : 0.343476\n",
            "Train Epoch : 8 | Batch Status : 14000/60000 (23%) | Loss : 0.244365\n",
            "Train Epoch : 8 | Batch Status : 15000/60000 (25%) | Loss : 0.241849\n",
            "Train Epoch : 8 | Batch Status : 16000/60000 (27%) | Loss : 0.251266\n",
            "Train Epoch : 8 | Batch Status : 17000/60000 (28%) | Loss : 0.212513\n",
            "Train Epoch : 8 | Batch Status : 18000/60000 (30%) | Loss : 0.194331\n",
            "Train Epoch : 8 | Batch Status : 19000/60000 (32%) | Loss : 0.144589\n",
            "Train Epoch : 8 | Batch Status : 20000/60000 (33%) | Loss : 0.273888\n",
            "Train Epoch : 8 | Batch Status : 21000/60000 (35%) | Loss : 0.234480\n",
            "Train Epoch : 8 | Batch Status : 22000/60000 (37%) | Loss : 0.204816\n",
            "Train Epoch : 8 | Batch Status : 23000/60000 (38%) | Loss : 0.425399\n",
            "Train Epoch : 8 | Batch Status : 24000/60000 (40%) | Loss : 0.325134\n",
            "Train Epoch : 8 | Batch Status : 25000/60000 (42%) | Loss : 0.366723\n",
            "Train Epoch : 8 | Batch Status : 26000/60000 (43%) | Loss : 0.186926\n",
            "Train Epoch : 8 | Batch Status : 27000/60000 (45%) | Loss : 0.269683\n",
            "Train Epoch : 8 | Batch Status : 28000/60000 (47%) | Loss : 0.245401\n",
            "Train Epoch : 8 | Batch Status : 29000/60000 (48%) | Loss : 0.300992\n",
            "Train Epoch : 8 | Batch Status : 30000/60000 (50%) | Loss : 0.307124\n",
            "Train Epoch : 8 | Batch Status : 31000/60000 (52%) | Loss : 0.236353\n",
            "Train Epoch : 8 | Batch Status : 32000/60000 (53%) | Loss : 0.220636\n",
            "Train Epoch : 8 | Batch Status : 33000/60000 (55%) | Loss : 0.276390\n",
            "Train Epoch : 8 | Batch Status : 34000/60000 (57%) | Loss : 0.321526\n",
            "Train Epoch : 8 | Batch Status : 35000/60000 (58%) | Loss : 0.265068\n",
            "Train Epoch : 8 | Batch Status : 36000/60000 (60%) | Loss : 0.288806\n",
            "Train Epoch : 8 | Batch Status : 37000/60000 (62%) | Loss : 0.259540\n",
            "Train Epoch : 8 | Batch Status : 38000/60000 (63%) | Loss : 0.208996\n",
            "Train Epoch : 8 | Batch Status : 39000/60000 (65%) | Loss : 0.313177\n",
            "Train Epoch : 8 | Batch Status : 40000/60000 (67%) | Loss : 0.216855\n",
            "Train Epoch : 8 | Batch Status : 41000/60000 (68%) | Loss : 0.300016\n",
            "Train Epoch : 8 | Batch Status : 42000/60000 (70%) | Loss : 0.220567\n",
            "Train Epoch : 8 | Batch Status : 43000/60000 (72%) | Loss : 0.346474\n",
            "Train Epoch : 8 | Batch Status : 44000/60000 (73%) | Loss : 0.155224\n",
            "Train Epoch : 8 | Batch Status : 45000/60000 (75%) | Loss : 0.242595\n",
            "Train Epoch : 8 | Batch Status : 46000/60000 (77%) | Loss : 0.307729\n",
            "Train Epoch : 8 | Batch Status : 47000/60000 (78%) | Loss : 0.277717\n",
            "Train Epoch : 8 | Batch Status : 48000/60000 (80%) | Loss : 0.207371\n",
            "Train Epoch : 8 | Batch Status : 49000/60000 (82%) | Loss : 0.244697\n",
            "Train Epoch : 8 | Batch Status : 50000/60000 (83%) | Loss : 0.189274\n",
            "Train Epoch : 8 | Batch Status : 51000/60000 (85%) | Loss : 0.503948\n",
            "Train Epoch : 8 | Batch Status : 52000/60000 (87%) | Loss : 0.408851\n",
            "Train Epoch : 8 | Batch Status : 53000/60000 (88%) | Loss : 0.176048\n",
            "Train Epoch : 8 | Batch Status : 54000/60000 (90%) | Loss : 0.451446\n",
            "Train Epoch : 8 | Batch Status : 55000/60000 (92%) | Loss : 0.273192\n",
            "Train Epoch : 8 | Batch Status : 56000/60000 (93%) | Loss : 0.302205\n",
            "Train Epoch : 8 | Batch Status : 57000/60000 (95%) | Loss : 0.285320\n",
            "Train Epoch : 8 | Batch Status : 58000/60000 (97%) | Loss : 0.375297\n",
            "Train Epoch : 8 | Batch Status : 59000/60000 (98%) | Loss : 0.474882\n",
            "Training time: 0m 6s\n",
            "==================\n",
            "Test set: Average loss : 0.0028, Accuracy : 9191/10000(92%)\n",
            "Tesing time: 0m 7s\n",
            "Train Epoch : 9 | Batch Status : 0/60000 (0%) | Loss : 0.228997\n",
            "Train Epoch : 9 | Batch Status : 1000/60000 (2%) | Loss : 0.269442\n",
            "Train Epoch : 9 | Batch Status : 2000/60000 (3%) | Loss : 0.180766\n",
            "Train Epoch : 9 | Batch Status : 3000/60000 (5%) | Loss : 0.202638\n",
            "Train Epoch : 9 | Batch Status : 4000/60000 (7%) | Loss : 0.296457\n",
            "Train Epoch : 9 | Batch Status : 5000/60000 (8%) | Loss : 0.260728\n",
            "Train Epoch : 9 | Batch Status : 6000/60000 (10%) | Loss : 0.380945\n",
            "Train Epoch : 9 | Batch Status : 7000/60000 (12%) | Loss : 0.208937\n",
            "Train Epoch : 9 | Batch Status : 8000/60000 (13%) | Loss : 0.269166\n",
            "Train Epoch : 9 | Batch Status : 9000/60000 (15%) | Loss : 0.247091\n",
            "Train Epoch : 9 | Batch Status : 10000/60000 (17%) | Loss : 0.346665\n",
            "Train Epoch : 9 | Batch Status : 11000/60000 (18%) | Loss : 0.276186\n",
            "Train Epoch : 9 | Batch Status : 12000/60000 (20%) | Loss : 0.270943\n",
            "Train Epoch : 9 | Batch Status : 13000/60000 (22%) | Loss : 0.218133\n",
            "Train Epoch : 9 | Batch Status : 14000/60000 (23%) | Loss : 0.188269\n",
            "Train Epoch : 9 | Batch Status : 15000/60000 (25%) | Loss : 0.409039\n",
            "Train Epoch : 9 | Batch Status : 16000/60000 (27%) | Loss : 0.223381\n",
            "Train Epoch : 9 | Batch Status : 17000/60000 (28%) | Loss : 0.229277\n",
            "Train Epoch : 9 | Batch Status : 18000/60000 (30%) | Loss : 0.375959\n",
            "Train Epoch : 9 | Batch Status : 19000/60000 (32%) | Loss : 0.372471\n",
            "Train Epoch : 9 | Batch Status : 20000/60000 (33%) | Loss : 0.275842\n",
            "Train Epoch : 9 | Batch Status : 21000/60000 (35%) | Loss : 0.236669\n",
            "Train Epoch : 9 | Batch Status : 22000/60000 (37%) | Loss : 0.288188\n",
            "Train Epoch : 9 | Batch Status : 23000/60000 (38%) | Loss : 0.367547\n",
            "Train Epoch : 9 | Batch Status : 24000/60000 (40%) | Loss : 0.236550\n",
            "Train Epoch : 9 | Batch Status : 25000/60000 (42%) | Loss : 0.205283\n",
            "Train Epoch : 9 | Batch Status : 26000/60000 (43%) | Loss : 0.385556\n",
            "Train Epoch : 9 | Batch Status : 27000/60000 (45%) | Loss : 0.281617\n",
            "Train Epoch : 9 | Batch Status : 28000/60000 (47%) | Loss : 0.364408\n",
            "Train Epoch : 9 | Batch Status : 29000/60000 (48%) | Loss : 0.285998\n",
            "Train Epoch : 9 | Batch Status : 30000/60000 (50%) | Loss : 0.332700\n",
            "Train Epoch : 9 | Batch Status : 31000/60000 (52%) | Loss : 0.113571\n",
            "Train Epoch : 9 | Batch Status : 32000/60000 (53%) | Loss : 0.351773\n",
            "Train Epoch : 9 | Batch Status : 33000/60000 (55%) | Loss : 0.372115\n",
            "Train Epoch : 9 | Batch Status : 34000/60000 (57%) | Loss : 0.270060\n",
            "Train Epoch : 9 | Batch Status : 35000/60000 (58%) | Loss : 0.258415\n",
            "Train Epoch : 9 | Batch Status : 36000/60000 (60%) | Loss : 0.301192\n",
            "Train Epoch : 9 | Batch Status : 37000/60000 (62%) | Loss : 0.248696\n",
            "Train Epoch : 9 | Batch Status : 38000/60000 (63%) | Loss : 0.232517\n",
            "Train Epoch : 9 | Batch Status : 39000/60000 (65%) | Loss : 0.298152\n",
            "Train Epoch : 9 | Batch Status : 40000/60000 (67%) | Loss : 0.242978\n",
            "Train Epoch : 9 | Batch Status : 41000/60000 (68%) | Loss : 0.221678\n",
            "Train Epoch : 9 | Batch Status : 42000/60000 (70%) | Loss : 0.202737\n",
            "Train Epoch : 9 | Batch Status : 43000/60000 (72%) | Loss : 0.147292\n",
            "Train Epoch : 9 | Batch Status : 44000/60000 (73%) | Loss : 0.290706\n",
            "Train Epoch : 9 | Batch Status : 45000/60000 (75%) | Loss : 0.342059\n",
            "Train Epoch : 9 | Batch Status : 46000/60000 (77%) | Loss : 0.345277\n",
            "Train Epoch : 9 | Batch Status : 47000/60000 (78%) | Loss : 0.284893\n",
            "Train Epoch : 9 | Batch Status : 48000/60000 (80%) | Loss : 0.267275\n",
            "Train Epoch : 9 | Batch Status : 49000/60000 (82%) | Loss : 0.173978\n",
            "Train Epoch : 9 | Batch Status : 50000/60000 (83%) | Loss : 0.291503\n",
            "Train Epoch : 9 | Batch Status : 51000/60000 (85%) | Loss : 0.308478\n",
            "Train Epoch : 9 | Batch Status : 52000/60000 (87%) | Loss : 0.198779\n",
            "Train Epoch : 9 | Batch Status : 53000/60000 (88%) | Loss : 0.325219\n",
            "Train Epoch : 9 | Batch Status : 54000/60000 (90%) | Loss : 0.365336\n",
            "Train Epoch : 9 | Batch Status : 55000/60000 (92%) | Loss : 0.326638\n",
            "Train Epoch : 9 | Batch Status : 56000/60000 (93%) | Loss : 0.476932\n",
            "Train Epoch : 9 | Batch Status : 57000/60000 (95%) | Loss : 0.317453\n",
            "Train Epoch : 9 | Batch Status : 58000/60000 (97%) | Loss : 0.205292\n",
            "Train Epoch : 9 | Batch Status : 59000/60000 (98%) | Loss : 0.272994\n",
            "Training time: 0m 6s\n",
            "==================\n",
            "Test set: Average loss : 0.0028, Accuracy : 9223/10000(92%)\n",
            "Tesing time: 0m 7s\n",
            "Train Epoch : 10 | Batch Status : 0/60000 (0%) | Loss : 0.197126\n",
            "Train Epoch : 10 | Batch Status : 1000/60000 (2%) | Loss : 0.428929\n",
            "Train Epoch : 10 | Batch Status : 2000/60000 (3%) | Loss : 0.202529\n",
            "Train Epoch : 10 | Batch Status : 3000/60000 (5%) | Loss : 0.418335\n",
            "Train Epoch : 10 | Batch Status : 4000/60000 (7%) | Loss : 0.222587\n",
            "Train Epoch : 10 | Batch Status : 5000/60000 (8%) | Loss : 0.232186\n",
            "Train Epoch : 10 | Batch Status : 6000/60000 (10%) | Loss : 0.367064\n",
            "Train Epoch : 10 | Batch Status : 7000/60000 (12%) | Loss : 0.403491\n",
            "Train Epoch : 10 | Batch Status : 8000/60000 (13%) | Loss : 0.241328\n",
            "Train Epoch : 10 | Batch Status : 9000/60000 (15%) | Loss : 0.212458\n",
            "Train Epoch : 10 | Batch Status : 10000/60000 (17%) | Loss : 0.274371\n",
            "Train Epoch : 10 | Batch Status : 11000/60000 (18%) | Loss : 0.404934\n",
            "Train Epoch : 10 | Batch Status : 12000/60000 (20%) | Loss : 0.247751\n",
            "Train Epoch : 10 | Batch Status : 13000/60000 (22%) | Loss : 0.286736\n",
            "Train Epoch : 10 | Batch Status : 14000/60000 (23%) | Loss : 0.249547\n",
            "Train Epoch : 10 | Batch Status : 15000/60000 (25%) | Loss : 0.393523\n",
            "Train Epoch : 10 | Batch Status : 16000/60000 (27%) | Loss : 0.336804\n",
            "Train Epoch : 10 | Batch Status : 17000/60000 (28%) | Loss : 0.334728\n",
            "Train Epoch : 10 | Batch Status : 18000/60000 (30%) | Loss : 0.380441\n",
            "Train Epoch : 10 | Batch Status : 19000/60000 (32%) | Loss : 0.381939\n",
            "Train Epoch : 10 | Batch Status : 20000/60000 (33%) | Loss : 0.206099\n",
            "Train Epoch : 10 | Batch Status : 21000/60000 (35%) | Loss : 0.492888\n",
            "Train Epoch : 10 | Batch Status : 22000/60000 (37%) | Loss : 0.377335\n",
            "Train Epoch : 10 | Batch Status : 23000/60000 (38%) | Loss : 0.244412\n",
            "Train Epoch : 10 | Batch Status : 24000/60000 (40%) | Loss : 0.266466\n",
            "Train Epoch : 10 | Batch Status : 25000/60000 (42%) | Loss : 0.364509\n",
            "Train Epoch : 10 | Batch Status : 26000/60000 (43%) | Loss : 0.263383\n",
            "Train Epoch : 10 | Batch Status : 27000/60000 (45%) | Loss : 0.164476\n",
            "Train Epoch : 10 | Batch Status : 28000/60000 (47%) | Loss : 0.255731\n",
            "Train Epoch : 10 | Batch Status : 29000/60000 (48%) | Loss : 0.382799\n",
            "Train Epoch : 10 | Batch Status : 30000/60000 (50%) | Loss : 0.334942\n",
            "Train Epoch : 10 | Batch Status : 31000/60000 (52%) | Loss : 0.317939\n",
            "Train Epoch : 10 | Batch Status : 32000/60000 (53%) | Loss : 0.184585\n",
            "Train Epoch : 10 | Batch Status : 33000/60000 (55%) | Loss : 0.229181\n",
            "Train Epoch : 10 | Batch Status : 34000/60000 (57%) | Loss : 0.140964\n",
            "Train Epoch : 10 | Batch Status : 35000/60000 (58%) | Loss : 0.264180\n",
            "Train Epoch : 10 | Batch Status : 36000/60000 (60%) | Loss : 0.205195\n",
            "Train Epoch : 10 | Batch Status : 37000/60000 (62%) | Loss : 0.302523\n",
            "Train Epoch : 10 | Batch Status : 38000/60000 (63%) | Loss : 0.316044\n",
            "Train Epoch : 10 | Batch Status : 39000/60000 (65%) | Loss : 0.362386\n",
            "Train Epoch : 10 | Batch Status : 40000/60000 (67%) | Loss : 0.215586\n",
            "Train Epoch : 10 | Batch Status : 41000/60000 (68%) | Loss : 0.220352\n",
            "Train Epoch : 10 | Batch Status : 42000/60000 (70%) | Loss : 0.143254\n",
            "Train Epoch : 10 | Batch Status : 43000/60000 (72%) | Loss : 0.350392\n",
            "Train Epoch : 10 | Batch Status : 44000/60000 (73%) | Loss : 0.297489\n",
            "Train Epoch : 10 | Batch Status : 45000/60000 (75%) | Loss : 0.334571\n",
            "Train Epoch : 10 | Batch Status : 46000/60000 (77%) | Loss : 0.205603\n",
            "Train Epoch : 10 | Batch Status : 47000/60000 (78%) | Loss : 0.239099\n",
            "Train Epoch : 10 | Batch Status : 48000/60000 (80%) | Loss : 0.219775\n",
            "Train Epoch : 10 | Batch Status : 49000/60000 (82%) | Loss : 0.195939\n",
            "Train Epoch : 10 | Batch Status : 50000/60000 (83%) | Loss : 0.258965\n",
            "Train Epoch : 10 | Batch Status : 51000/60000 (85%) | Loss : 0.369145\n",
            "Train Epoch : 10 | Batch Status : 52000/60000 (87%) | Loss : 0.247725\n",
            "Train Epoch : 10 | Batch Status : 53000/60000 (88%) | Loss : 0.332460\n",
            "Train Epoch : 10 | Batch Status : 54000/60000 (90%) | Loss : 0.438369\n",
            "Train Epoch : 10 | Batch Status : 55000/60000 (92%) | Loss : 0.313649\n",
            "Train Epoch : 10 | Batch Status : 56000/60000 (93%) | Loss : 0.299573\n",
            "Train Epoch : 10 | Batch Status : 57000/60000 (95%) | Loss : 0.187417\n",
            "Train Epoch : 10 | Batch Status : 58000/60000 (97%) | Loss : 0.393218\n",
            "Train Epoch : 10 | Batch Status : 59000/60000 (98%) | Loss : 0.267992\n",
            "Training time: 0m 6s\n",
            "==================\n",
            "Test set: Average loss : 0.0028, Accuracy : 9223/10000(92%)\n",
            "Tesing time: 0m 7s\n",
            "Total time : 0m  7s \n",
            "Model was trained on cpu!\n"
          ]
        }
      ]
    }
  ]
}